{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First try with given scripts (BAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open our embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = np.load('embeddings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab.pkl\", \"rb\") as f:\n",
    "        vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize positive tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lines_pos = sum(1 for line in open('Datasets/twitter-datasets/train_pos_full.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = np.zeros((num_lines_pos,emb.shape[1]))\n",
    "with open('Datasets/twitter-datasets/train_pos.txt') as f:\n",
    "    for line_index, line in enumerate(f):\n",
    "        words = line.split()\n",
    "        index = [vocab[word] for word in words if word in vocab.keys()]\n",
    "        line_fet = np.mean(np.array([emb[i] for i in index]),axis = 0)\n",
    "        train_pos[line_index] = line_fet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove_pos = np.unique([x for x,y in np.argwhere(np.isnan(train_pos))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_2 = np.delete(train_pos,index_to_remove_pos,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lines_neg = sum(1 for line in open('Datasets/twitter-datasets/train_neg_full.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg = np.zeros((num_lines_neg,emb.shape[1]))\n",
    "with open('Datasets/twitter-datasets/train_neg.txt') as f:\n",
    "    for line_index, line in enumerate(f):\n",
    "        words = line.split()\n",
    "        index = [vocab[word] for word in words if word in vocab.keys()]\n",
    "        line_fet = np.mean(np.array([emb[i] for i in index]),axis = 0)\n",
    "        train_neg[line_index] = line_fet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove_neg = np.unique([x for x,y in np.argwhere(np.isnan(train_neg))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_2 = np.delete(train_neg,index_to_remove_neg,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get total training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_pos_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-b76ff27f5f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pos_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_neg_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pos_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_neg_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_pos_2' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.vstack((train_pos_2,train_neg_2))\n",
    "y_pos = np.ones(train_pos_2.shape[0])\n",
    "y_neg = np.repeat(-1,train_neg_2.shape[0])\n",
    "Y = np.hstack((y_pos,y_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X',X)\n",
    "np.save('Y',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X.npy')\n",
    "Y = np.load('Y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    poly = np.ones((len(x), 1))\n",
    "    for deg in range(1, degree+1):\n",
    "        poly = np.c_[poly, np.power(x, deg)]\n",
    "    return poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = build_poly(X,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=True, order='C')\n",
    "X = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = std.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train',X_train)\n",
    "np.save('X_test',X_test)\n",
    "np.save('Y_train',Y_train)\n",
    "np.save('Y_test',Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "Y_train = np.load('Y_train.npy')\n",
    "Y_test = np.load('Y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi = LogisticRegression(penalty='l2', dual=False, tol=10e-10, C=0.5, fit_intercept=True, intercept_scaling=1, \n",
    "                          class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', \n",
    "                          verbose=1, warm_start=False, n_jobs=None, l1_ratio=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(penalty='l2', loss='squared_hinge', dual=False, tol=10e-10, C=0.5, multi_class='ovr', \n",
    "                fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=1, random_state=None, \n",
    "                max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize test tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lines_test = sum(1 for line in open('Datasets/twitter-datasets/test_data.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.zeros((num_lines_test,emb.shape[1]))\n",
    "with open('Datasets/twitter-datasets/test_data.txt') as f:\n",
    "    for line_index, line in enumerate(f):\n",
    "        line = line.split(',',1)[1]\n",
    "        words = line.split()\n",
    "        index = [vocab[word] for word in words if word in vocab.keys()]\n",
    "        line_fet = np.mean(np.array([emb[i] for i in index]),axis = 0)\n",
    "        test[line_index] = line_fet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove_test = np.unique([x for x,y in np.argwhere(np.isnan(test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = np.delete(test,index_to_remove_test,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = std.fit_transform(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = build_poly(test_2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(test_2)\n",
    "prediction_2 = np.insert(prediction, index_to_remove_test -1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "## Vocabulary vectorizing\n",
    "Read words in positive and neg tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import gensim\n",
    "import logging\n",
    "import tempfile\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Datasets/twitter-datasets/train_pos_cleaned.txt\")\n",
    "tweets_pos = [line.split() for line in f.readlines()]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Datasets/twitter-datasets/train_neg_cleaned.txt\")\n",
    "tweets_neg = [line.split() for line in f.readlines()]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Word2vec\n",
    "size = 300\n",
    "min_count = 5\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 16:01:52,170 : INFO : collecting all words and their counts\n",
      "2019-12-09 16:01:52,174 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-12-09 16:01:52,204 : INFO : PROGRESS: at sentence #10000, processed 135260 words, keeping 13571 word types\n",
      "2019-12-09 16:01:52,234 : INFO : PROGRESS: at sentence #20000, processed 273051 words, keeping 21361 word types\n",
      "2019-12-09 16:01:52,264 : INFO : PROGRESS: at sentence #30000, processed 409541 words, keeping 27684 word types\n",
      "2019-12-09 16:01:52,293 : INFO : PROGRESS: at sentence #40000, processed 545956 words, keeping 33450 word types\n",
      "2019-12-09 16:01:52,324 : INFO : PROGRESS: at sentence #50000, processed 682534 words, keeping 38692 word types\n",
      "2019-12-09 16:01:52,353 : INFO : PROGRESS: at sentence #60000, processed 819941 words, keeping 43497 word types\n",
      "2019-12-09 16:01:52,381 : INFO : PROGRESS: at sentence #70000, processed 956698 words, keeping 48110 word types\n",
      "2019-12-09 16:01:52,409 : INFO : PROGRESS: at sentence #80000, processed 1092945 words, keeping 52418 word types\n",
      "2019-12-09 16:01:52,437 : INFO : PROGRESS: at sentence #90000, processed 1229486 words, keeping 56599 word types\n",
      "2019-12-09 16:01:52,472 : INFO : PROGRESS: at sentence #100000, processed 1393849 words, keeping 65734 word types\n",
      "2019-12-09 16:01:52,507 : INFO : PROGRESS: at sentence #110000, processed 1559675 words, keeping 73352 word types\n",
      "2019-12-09 16:01:52,547 : INFO : PROGRESS: at sentence #120000, processed 1724745 words, keeping 80130 word types\n",
      "2019-12-09 16:01:52,587 : INFO : PROGRESS: at sentence #130000, processed 1890466 words, keeping 86589 word types\n",
      "2019-12-09 16:01:52,628 : INFO : PROGRESS: at sentence #140000, processed 2055254 words, keeping 92437 word types\n",
      "2019-12-09 16:01:52,667 : INFO : PROGRESS: at sentence #150000, processed 2220044 words, keeping 98175 word types\n",
      "2019-12-09 16:01:52,705 : INFO : PROGRESS: at sentence #160000, processed 2384738 words, keeping 103715 word types\n",
      "2019-12-09 16:01:52,744 : INFO : PROGRESS: at sentence #170000, processed 2550151 words, keeping 108875 word types\n",
      "2019-12-09 16:01:52,783 : INFO : PROGRESS: at sentence #180000, processed 2715242 words, keeping 113787 word types\n",
      "2019-12-09 16:01:52,789 : INFO : collected 114427 word types from a corpus of 2736336 raw words and 181290 sentences\n",
      "2019-12-09 16:01:52,790 : INFO : Loading a fresh vocabulary\n",
      "2019-12-09 16:01:52,857 : INFO : effective_min_count=5 retains 19530 unique words (17% of original 114427, drops 94897)\n",
      "2019-12-09 16:01:52,858 : INFO : effective_min_count=5 leaves 2602987 word corpus (95% of original 2736336, drops 133349)\n",
      "2019-12-09 16:01:52,914 : INFO : deleting the raw counts dictionary of 114427 items\n",
      "2019-12-09 16:01:52,916 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2019-12-09 16:01:52,917 : INFO : downsampling leaves estimated 1977548 word corpus (76.0% of prior 2602987)\n",
      "2019-12-09 16:01:52,974 : INFO : estimated required memory for 19530 words and 100 dimensions: 25389000 bytes\n",
      "2019-12-09 16:01:52,976 : INFO : resetting layer weights\n",
      "2019-12-09 16:01:56,574 : INFO : training model with 1 workers on 19530 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-12-09 16:01:57,588 : INFO : EPOCH 1 - PROGRESS: at 29.47% examples, 524674 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:01:58,593 : INFO : EPOCH 1 - PROGRESS: at 59.32% examples, 546689 words/s, in_qsize 2, out_qsize 0\n",
      "2019-12-09 16:01:59,597 : INFO : EPOCH 1 - PROGRESS: at 86.36% examples, 557577 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:00,103 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:00,103 : INFO : EPOCH - 1 : training on 2736336 raw words (1977503 effective words) took 3.5s, 560882 effective words/s\n",
      "2019-12-09 16:02:01,112 : INFO : EPOCH 2 - PROGRESS: at 31.06% examples, 556498 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:02,114 : INFO : EPOCH 2 - PROGRESS: at 61.62% examples, 574026 words/s, in_qsize 2, out_qsize 0\n",
      "2019-12-09 16:02:03,115 : INFO : EPOCH 2 - PROGRESS: at 87.34% examples, 566684 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:03,574 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:03,575 : INFO : EPOCH - 2 : training on 2736336 raw words (1977346 effective words) took 3.5s, 570129 effective words/s\n",
      "2019-12-09 16:02:04,585 : INFO : EPOCH 3 - PROGRESS: at 34.29% examples, 613353 words/s, in_qsize 2, out_qsize 0\n",
      "2019-12-09 16:02:05,597 : INFO : EPOCH 3 - PROGRESS: at 59.98% examples, 552876 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:06,601 : INFO : EPOCH 3 - PROGRESS: at 83.00% examples, 533149 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:07,286 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:07,286 : INFO : EPOCH - 3 : training on 2736336 raw words (1976776 effective words) took 3.7s, 533187 effective words/s\n",
      "2019-12-09 16:02:08,294 : INFO : EPOCH 4 - PROGRESS: at 33.47% examples, 599998 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:09,299 : INFO : EPOCH 4 - PROGRESS: at 63.97% examples, 598359 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:10,306 : INFO : EPOCH 4 - PROGRESS: at 90.69% examples, 589014 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:10,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:10,643 : INFO : EPOCH - 4 : training on 2736336 raw words (1976950 effective words) took 3.4s, 589681 effective words/s\n",
      "2019-12-09 16:02:11,650 : INFO : EPOCH 5 - PROGRESS: at 33.87% examples, 607468 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:12,653 : INFO : EPOCH 5 - PROGRESS: at 63.30% examples, 592070 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:13,662 : INFO : EPOCH 5 - PROGRESS: at 88.68% examples, 574816 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:14,208 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:14,209 : INFO : EPOCH - 5 : training on 2736336 raw words (1977737 effective words) took 3.6s, 555129 effective words/s\n",
      "2019-12-09 16:02:15,215 : INFO : EPOCH 6 - PROGRESS: at 31.06% examples, 558452 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:16,221 : INFO : EPOCH 6 - PROGRESS: at 55.99% examples, 513132 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:17,233 : INFO : EPOCH 6 - PROGRESS: at 81.33% examples, 521961 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:17,934 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:17,935 : INFO : EPOCH - 6 : training on 2736336 raw words (1976706 effective words) took 3.7s, 531258 effective words/s\n",
      "2019-12-09 16:02:18,947 : INFO : EPOCH 7 - PROGRESS: at 31.86% examples, 569351 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:19,958 : INFO : EPOCH 7 - PROGRESS: at 63.30% examples, 588595 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:20,966 : INFO : EPOCH 7 - PROGRESS: at 88.36% examples, 570634 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:21,389 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:21,390 : INFO : EPOCH - 7 : training on 2736336 raw words (1978525 effective words) took 3.5s, 573300 effective words/s\n",
      "2019-12-09 16:02:22,398 : INFO : EPOCH 8 - PROGRESS: at 32.67% examples, 585385 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:23,408 : INFO : EPOCH 8 - PROGRESS: at 59.98% examples, 554003 words/s, in_qsize 2, out_qsize 0\n",
      "2019-12-09 16:02:24,413 : INFO : EPOCH 8 - PROGRESS: at 86.02% examples, 555212 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:24,932 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:24,932 : INFO : EPOCH - 8 : training on 2736336 raw words (1978010 effective words) took 3.5s, 558789 effective words/s\n",
      "2019-12-09 16:02:25,940 : INFO : EPOCH 9 - PROGRESS: at 32.26% examples, 578558 words/s, in_qsize 2, out_qsize 0\n",
      "2019-12-09 16:02:26,947 : INFO : EPOCH 9 - PROGRESS: at 62.62% examples, 583765 words/s, in_qsize 2, out_qsize 0\n",
      "2019-12-09 16:02:27,957 : INFO : EPOCH 9 - PROGRESS: at 88.36% examples, 571807 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:28,413 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:28,413 : INFO : EPOCH - 9 : training on 2736336 raw words (1978200 effective words) took 3.5s, 568893 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 16:02:29,426 : INFO : EPOCH 10 - PROGRESS: at 32.67% examples, 583116 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:30,432 : INFO : EPOCH 10 - PROGRESS: at 62.29% examples, 578838 words/s, in_qsize 2, out_qsize 0\n",
      "2019-12-09 16:02:31,443 : INFO : EPOCH 10 - PROGRESS: at 89.36% examples, 577511 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:31,854 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:31,855 : INFO : EPOCH - 10 : training on 2736336 raw words (1977467 effective words) took 3.4s, 575140 effective words/s\n",
      "2019-12-09 16:02:32,868 : INFO : EPOCH 11 - PROGRESS: at 32.67% examples, 582330 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:33,872 : INFO : EPOCH 11 - PROGRESS: at 62.96% examples, 586041 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:34,878 : INFO : EPOCH 11 - PROGRESS: at 88.68% examples, 573903 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:35,315 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:35,316 : INFO : EPOCH - 11 : training on 2736336 raw words (1976604 effective words) took 3.5s, 571578 effective words/s\n",
      "2019-12-09 16:02:36,330 : INFO : EPOCH 12 - PROGRESS: at 33.47% examples, 597535 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:37,339 : INFO : EPOCH 12 - PROGRESS: at 62.29% examples, 577912 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:38,346 : INFO : EPOCH 12 - PROGRESS: at 89.36% examples, 577699 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:38,736 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:38,737 : INFO : EPOCH - 12 : training on 2736336 raw words (1977671 effective words) took 3.4s, 578804 effective words/s\n",
      "2019-12-09 16:02:39,741 : INFO : EPOCH 13 - PROGRESS: at 31.46% examples, 566350 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:40,744 : INFO : EPOCH 13 - PROGRESS: at 59.32% examples, 550178 words/s, in_qsize 2, out_qsize 0\n",
      "2019-12-09 16:02:41,749 : INFO : EPOCH 13 - PROGRESS: at 86.36% examples, 559497 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:42,350 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:42,351 : INFO : EPOCH - 13 : training on 2736336 raw words (1977339 effective words) took 3.6s, 547740 effective words/s\n",
      "2019-12-09 16:02:43,363 : INFO : EPOCH 14 - PROGRESS: at 30.67% examples, 546720 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:44,371 : INFO : EPOCH 14 - PROGRESS: at 60.31% examples, 557080 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:45,371 : INFO : EPOCH 14 - PROGRESS: at 87.34% examples, 565048 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:45,830 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:45,831 : INFO : EPOCH - 14 : training on 2736336 raw words (1977247 effective words) took 3.5s, 568666 effective words/s\n",
      "2019-12-09 16:02:46,839 : INFO : EPOCH 15 - PROGRESS: at 33.07% examples, 592969 words/s, in_qsize 2, out_qsize 0\n",
      "2019-12-09 16:02:47,845 : INFO : EPOCH 15 - PROGRESS: at 62.29% examples, 580338 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:48,852 : INFO : EPOCH 15 - PROGRESS: at 89.02% examples, 576954 words/s, in_qsize 1, out_qsize 0\n",
      "2019-12-09 16:02:49,269 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-09 16:02:49,269 : INFO : EPOCH - 15 : training on 2736336 raw words (1977495 effective words) took 3.4s, 575727 effective words/s\n",
      "2019-12-09 16:02:49,270 : INFO : training on a 41045040 raw words (29661576 effective words) took 52.7s, 562905 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences=tweets_pos + tweets_neg, corpus_file=None, size=size, alpha=0.025, window=5,\n",
    "                          min_count=min_count, max_vocab_size=None, sample=0.001, seed=1, workers=1, min_alpha=0.0001, sg=0,\n",
    "                          hs=0, negative=5, ns_exponent=0.75, cbow_mean=1, iter=epoch, null_word=0, trim_rule=None,\n",
    "                          sorted_vocab=1, batch_words=10000, compute_loss=False, callbacks=(), max_final_vocab=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeeding\n",
    "### Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/etienne/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/etienne/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "train_pos = np.zeros((len(tweets_pos),size))\n",
    "for index, tokens in enumerate(tweets_pos):\n",
    "    vect = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    train_pos[index] = np.mean(vect, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove_pos = np.unique([x for x,y in np.argwhere(np.isnan(train_pos))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_2 = np.delete(train_pos,index_to_remove_pos,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg = np.zeros((len(tweets_neg),size))\n",
    "for index, tokens in enumerate(tweets_neg):\n",
    "    vect = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    train_neg[index] = np.mean(vect, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove_neg = np.unique([x for x,y in np.argwhere(np.isnan(train_neg))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_2 = np.delete(train_neg,index_to_remove_neg,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Datasets/twitter-datasets/test_data.txt\")\n",
    "tweets_test = [line.split() for line in f.readlines()]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.zeros((len(tweets_test),size))\n",
    "for index, tokens in enumerate(tweets_test):\n",
    "    vect = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    test[index] = np.mean(vect, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove_test = np.unique([x for x,y in np.argwhere(np.isnan(test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = np.delete(test,index_to_remove_test,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine\n",
    "Combine pos and neg to have full training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((train_pos_2,train_neg_2))\n",
    "y_pos = np.ones(train_pos_2.shape[0])\n",
    "y_neg = np.repeat(-1,train_neg_2.shape[0])\n",
    "Y = np.hstack((y_pos,y_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Word2vec_X',X)\n",
    "np.save('Word2vec_Y',Y)\n",
    "np.save('Word2vec_test',test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('Word2vec_X.npy')\n",
    "Y = np.load('Word2vec_Y.npy')\n",
    "test_2 = np.load('Word2vec_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Logistic Regression with Cross-validation so don't need to split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10e2, fit_intercept=True, intercept_scaling=1,\n",
    "                         class_weight=None, random_state=None, solver='sag', max_iter=100000, multi_class='ovr',\n",
    "                         verbose=0, warm_start=False, n_jobs=-1, l1_ratio=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logiCV = LogisticRegressionCV(Cs=5, fit_intercept=True, cv=4, dual=False, penalty='l2', scoring=None,\n",
    "                     solver='sag', tol=0.0001, max_iter=10000, class_weight=None, n_jobs=-1, verbose=0,\n",
    "                     refit=True, intercept_scaling=1.0, multi_class='ovr', random_state=None, l1_ratios=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logiCV.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Datasets/twitter-datasets/test_data.txt\")\n",
    "tweets = [line for line in f.readlines()]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i dunno justin read my mention or not . only justin and god knows about that , but i hope you will follow me #believe 15\\n',\n",
       " \"because your logic is so dumb , i won't even crop out your name or your photo . tsk . <url>\\n\",\n",
       " '\" just put casper in a box ! \" looved the battle ! #crakkbitch\\n',\n",
       " \"thanks sir > > don't trip lil mama ... just keep doin ya thang !\\n\",\n",
       " 'visiting my brother tmr is the bestest birthday gift eveerrr ! ! !\\n',\n",
       " 'yay ! ! #lifecompleted . tweet / facebook me to let me know please\\n',\n",
       " '#1dnextalbumtitle : feel for you / rollercoaster of life . song cocept : life , #yolo , becoming famous ? <3 14 #followmeplz ! <3 x15\\n',\n",
       " \"workin hard or hardly workin rt at hardee's with my future coworker <user>\\n\",\n",
       " \"i saw . i'll be replying in a bit .\\n\",\n",
       " 'this is were i belong\\n',\n",
       " 'anddd to cheer #nationals2013 ?\\n',\n",
       " 'we send an invitation to shop on-line ! here you will find everything you need - without leaving home ... <url>\\n',\n",
       " 'just woke up , finna go to church\\n',\n",
       " 'agreed ! 12 more days left tho\\n',\n",
       " 'monet with katemelo\\n',\n",
       " 'like dammm lexis u got a lot to say when ur on twitter lol\\n',\n",
       " 'grateful today for a dream fulfilled ! ! my heart is so full - first 3 completed tracks have arrived back from new york ! #yeslord !\\n',\n",
       " 'at home affairs shall do it later\\n',\n",
       " 'barca bout to beat real madrid on saturday doe\\n',\n",
       " 'a lot of parts of asia . especially rats that live in the country and live on grains . supposed to be quite tasty .\\n',\n",
       " \"i wasn't even sleeping . so shut cho ole go back to sleep lookin ass\\n\",\n",
       " 'i have the worlds best dad . <3\\n',\n",
       " 'ab jaeyay werna meeting khatam hi hojaeygi baaqi ki buttering baad may karaygay hum sab\\n',\n",
       " 'no one doubts that ability !\\n',\n",
       " 'check my tweet pic out . that was the outfit before . this is it after\\n',\n",
       " \"just got my mid-term and i'm impressed ! ! #happy\\n\",\n",
       " 'my summer days : 1 . ) work from 10:30- 2:30 ish .. 2 . ) home , shower , & eat ... 3 . ) go out till whenever and do it all over again\\n',\n",
       " 'lol nooo .. food is ur friend\\n',\n",
       " '#16millionbritneyfan rt and tweet\\n',\n",
       " \"but seriously though .. it's called vanity fairest\\n\",\n",
       " \"lol chloe :') ill teach yous to cook , you'll be pros by the end of it !\\n\",\n",
       " 'lol , im finna eat something ... chicken\\n',\n",
       " \"any questions for me ? just put preston down for a short nap and mikes not home for another hour , feel like answer q's ! ! make ' em original\\n\",\n",
       " 'friday is payday & 4/20 ? ? hell yeah #reasons2dothebirdmanhandrub\\n',\n",
       " 'thank you again love & & i def will get that done ) i have plenty i want framed lols\\n',\n",
       " \"i'm very week thanksss ! what you up to ? xxx\\n\",\n",
       " \"#ff to my good , hilarious , sweet and kind friend , who loves toilet paper , he's always made me laugh when i needed to ! <3\\n\",\n",
       " 'apparently not )\\n',\n",
       " 'i live my life on the quote \" live life for the moment cos everything else is uncertain \" - louis tomlinson\\n',\n",
       " \"i can't wait to see it can you please notice or follow me ?\\n\",\n",
       " \"but they couldn't be bigger than ' s ones\\n\",\n",
       " '#yougetmajorpointsif you are olivia brown\\n',\n",
       " \"ty as well ! i don't know what i would do without you too my sister in christ ! you are truly a blessing to the kingdom !\\n\",\n",
       " 'i love southall travel , and before i visit southall i visit <url> first\\n',\n",
       " 'we care a lot for the ones you love ... good morning <url> share it with your friends . <url>\\n',\n",
       " 'i love you ! if you love me to please rt\\n',\n",
       " 'are you a blonde yet ?\\n',\n",
       " \"wait my brother has one ! let's get a picture\\n\",\n",
       " \"if i dont do it first thing i won't do it ! plus i beat the bridge traffic\\n\",\n",
       " 'japan has some of the nicest rivers ! <url>\\n',\n",
       " 'oh hi please follow me\\n',\n",
       " 'my new drawing based on just waiting for knowing her fav color <url>\\n',\n",
       " \"i haven't seen myself though and they didn't ask which is a bit annoying :p haha , ooo really ? why ?\\n\",\n",
       " 'i just need 17 more followers ! please follow to get me to 500 followers before saturday and to support ben kelly #teamjessie #thevoiceuk\\n',\n",
       " 'i want a dream like thatd ; hahah yolo . xx\\n',\n",
       " \"well mr . schmidt / knight , aren't you the charmer ? you just made my day five gazillion times better . love you !\\n\",\n",
       " \"no probs hope it's all going well !\\n\",\n",
       " 'watching now hehe ) )\\n',\n",
       " 'off to shower then bed , night night bbs\\n',\n",
       " \"be happy in front of people who don't like you , it kills them .\\n\",\n",
       " 'me and martina are gonna make a video to call me maybe with the boys\\n',\n",
       " 'laying with my little cuddle buddy tonight <url>\\n',\n",
       " \"aahh , sorry love ... but i know you'll ace them . )\\n\",\n",
       " 'how are #zuers holding up in the midst of all the midterms ? remember the secret to success is a good night sleep\\n',\n",
       " 'watching the first 48 , so is half my followers lol\\n',\n",
       " 'can i get a follow back from a fellow #twfanmily member please\\n',\n",
       " 'okay but next me you me are definitely hanging out\\n',\n",
       " 'i just figured out i have the same birthday as mike the situation from jersey shore .. but july 4th is a good day because i get fireworks\\n',\n",
       " 'dude i dident say one thing to her today ! ? ! and she starts trying to say shit ? k .\\n',\n",
       " \"can i get 3 more followers tonight :d i'm nice . you'll like my tweets . i'll try my best\\n\",\n",
       " 'yeah i was quite surprised too . even called the score .\\n',\n",
       " 'after school with my girls <user>\\n',\n",
       " 'hehe <3 well hello there\\n',\n",
       " \"i'll be sleeping there\\n\",\n",
       " 'i love that he thought of me and his sweet proud face when he handed them to me made me tear up ! xoxoxo\\n',\n",
       " '#smackkk like that\\n',\n",
       " 'when people judge & criticize you , just remember it says nothing about you & everything about them\\n',\n",
       " 'umm duh ! i told you ! u need to come to cracow\\n',\n",
       " 'aww , you are a very sweet kind . smurf . i love you too & talking with u lifts my spirits as well . <3\\n',\n",
       " 'give her that dope dick , till she can feel it in her stomach , eyes rolling back & toes curling\\n',\n",
       " \"happy 4.20 for reals . i'm sparking in the name of .\\n\",\n",
       " \"i know ! can't believe it myself ! i'll send you a pic of the hall !\\n\",\n",
       " 'rt help us trend jaomikay and kathrynbernardoasmikay thankyou ! <user>\\n',\n",
       " 'i got 2 cold 40s in the fridge\\n',\n",
       " 'heres to the kids who hate giving speeches\\n',\n",
       " 'gunun sorusu where is my mind <url> via <user>\\n',\n",
       " \"when i'm old enough i'm going on long lost family\\n\",\n",
       " '.. glad ur ok and it sure is can almost c it nite nite\\n',\n",
       " 'meal + cinema with katie\\n',\n",
       " 'so i thought since your a bieber fan and there arnt many at our school i assumed that was your team\\n',\n",
       " \"smiles what's up chikaroo ? xx\\n\",\n",
       " 'i know i was in spanish\\n',\n",
       " \"it's once every 24 hours\\n\",\n",
       " \"follow cos she's a fully sick dog\\n\",\n",
       " 'thanks for the super sexy gold show ladies ! have fun shopping !\\n',\n",
       " 'always a pleasure marie\\n',\n",
       " \"i'm not sure if they are really aware of twitter . a hyena on nitrous oxide might confuse them .\\n\",\n",
       " \"i dm'd you what to do get your followers to follow you on my your new twitter . where is this shindig ? x\\n\",\n",
       " \"i can't wait til she moves back to san antonio\\n\",\n",
       " 'so hate the weather . pwede bang summer na malamig ! ? haist \" i so love summer ! \"\\n',\n",
       " '9:19 my time and <user>\\n',\n",
       " 'we need to book our t4 on the beach tickets ! ! ! #excited\\n',\n",
       " 'oh wow ! ! is it like saturday over there ! ? sorry forgot about the time difference and omfg if 1d came in i would die ... xx\\n',\n",
       " 'black with a touch of blue <url>\\n',\n",
       " \"i wouldn't mind drinking these cause they're cute ! <url>\\n\",\n",
       " 'aight thanks sweetz rt yeah that 1\\n',\n",
       " 'adam west ? ? think we are forgetting\\n',\n",
       " 'this describes me this morning\\n',\n",
       " \"jessica makes me feel #foreveralone . but it's all good cause i know she'll be right next to me ... forever ... alone ;d aha\\n\",\n",
       " 'oh hahahah thanks\\n',\n",
       " 'try to find out where it is !\\n',\n",
       " 'u r supposed to be awake at this hour ! hahaha come and join me ! im on my #insommia & u have a #lifeofcallcenter )\\n',\n",
       " 'so ... happy birthday how old are you , swiftie ?\\n',\n",
       " \"can't wait for this trip to la\\n\",\n",
       " 'whatever peasant x\\n',\n",
       " \"that's embarrassing\\n\",\n",
       " 'i bet #dadforgottogetkerosine is trending worldwide after that tweet #stupidhashtag\\n',\n",
       " 'fckk both of yall okay , my titties big ! #dd <--- #wishfulthinking\\n',\n",
       " 'may all angels guard & guide ur way night & day\\n',\n",
       " 'lol jk jk kimmy ill try to get you some food wen i see you\\n',\n",
       " 'i am a muslim and i am proud to be one ! ! !\\n',\n",
       " 'rouninblogs : photo : stickers came in ! and doin work on a new shirt comin up soon #rouninapparel #rounin #design ... ...\\n',\n",
       " \"follow she's simply amazing and deserves more followers\\n\",\n",
       " 'kiss mhee real slow & get down & blow mhy mind\\n',\n",
       " 'lmao weird but true its crazy how i can always relate to the weird stuff tweet about ... smh lol\\n',\n",
       " 'zed ! msh aja ! ( rt this is lipbalm , not salep kutu air ... ... <url>\\n',\n",
       " 'i miss you nia ! and yes , hopefully ill see you at my grad love you !\\n',\n",
       " 'i wanna buy that \" stop wars \" t-shirt . bought one . we were supposed to wear it psychology together\\n',\n",
       " 'no problem babe :d thanks dear !\\n',\n",
       " 'subway date with #workflow\\n',\n",
       " 'omg that\\'s my shit ! .. rt \" making good love , , avant .. > most def is on the baby making playlist lol \"\\n',\n",
       " 'when i think of my future while closing my eyes , i can see you and me . together\\n',\n",
       " \"you're welcome ! and thanks for sharing ! looking forward to that . have a great day and stay fit !\\n\",\n",
       " '\" i am now a member of global 14 good \" .. ill b a member soon\\n',\n",
       " 'its all good blacky !\\n',\n",
       " \"thank you alison . i hope you're well + happy #ff to you too x\\n\",\n",
       " \"ooo this story is getting good can't wait for more hee hee xoxox\\n\",\n",
       " 'really ? wow thats good .. its a really nice article x\\n',\n",
       " 'writing poems about pycc #toolive chad saying \" too live \" > > > #realthug\\n',\n",
       " 'be a lady in the streets , but a freak in the sheets\\n',\n",
       " 'are you getting that tattoo ? ? <3\\n',\n",
       " 'talks with emmanuel / mayo whewww !\\n',\n",
       " '#thingsrkellysingsabout get ready fa that real gold shower\\n',\n",
       " \"under my covers there's a new adventure every time\\n\",\n",
       " 'laynn in the briefs\\n',\n",
       " 'follow me on instagram : <user>\\n',\n",
       " 'all the above !\\n',\n",
       " \"i'm proud to say that i never smoked in my life and i never will .\\n\",\n",
       " 'that i can bring home to my mom\\n',\n",
       " 'got my magazines in the mail today ! girls , you can relate . <url>\\n',\n",
       " 'when i think of his name all i can do is smile\\n',\n",
       " 'i see imma have to get a bitch prom taken away ...\\n',\n",
       " 'either way you win . get it girl\\n',\n",
       " \"are you all righthaha ! you're so excited , right of course , we can't wait , too . ) )\\n\",\n",
       " \"lol i'm still reassuringly trotskyist 95 % of the time\\n\",\n",
       " 'treats from an ed client who has been baking ! woohoo <url>\\n',\n",
       " 'no she will cuz its me\\n',\n",
       " '#waystobeginsex talking hella shit guy tell girl to shut up she says make me he says i will with this d * ck she talks more shit ...\\n',\n",
       " \"thanks so much bay , i love you too ! ! can't wait to see you ! !\\n\",\n",
       " 'want to text\\n',\n",
       " 'could you please follow me ? ? if you do i will dance around like an idiot , like i did when luke did ! please <3 #28\\n',\n",
       " \"please follow you'll love her ! !\\n\",\n",
       " '\" no one does me better than me lool \" is this banter ?\\n',\n",
       " 'lmao ! that made my day ! rt i got board so i thought i would practice my awesome dance moves lol <url>\\n',\n",
       " '... #bap site is sick . slide thru & check it out ! ! 1love\\n',\n",
       " 'is having lyrics jus need to think if i deffo want these certain lyrics\\n',\n",
       " ': haha .. its ok . i was just kidding . btw , am too a banglorean\\n',\n",
       " \"many thanks t ! i am very appreciative sorry it woke you ! how's eddy ? ?\\n\",\n",
       " \"i am hold your excitement i know there's a lot haha\\n\",\n",
       " 'when a girl can take jokes , make you laugh , and make you feel like a king ; then shes meant to be your queen ! <3\\n',\n",
       " 'well , thank you ! ! !\\n',\n",
       " '- smh .. ima still eat this icecream . double strawberry .\\n',\n",
       " 'well it happens alot , so alot of picture opportunity\\n',\n",
       " 'true , but bacon infused bourbon and a little maple syrup make it real tasty .\\n',\n",
       " 'how many mexicans does it take to change a lightbulb ? just juan #joketweet\\n',\n",
       " 'anyways , hope everybody passed their grad exams\\n',\n",
       " 'about to be home alonee ! #yess\\n',\n",
       " '#yes i guess it is #patient that pays off in the long run #imintoyou\\n',\n",
       " 'lol coz the songs called \" love love love \"\\n',\n",
       " 'haha it hasnt blown up like this in a while , so thanks for that lol\\n',\n",
       " \"happy birthday i love you with all my heart and stay army strong ! ! ! can't wait to see you again\\n\",\n",
       " 'watching freedom writers in advisory\\n',\n",
       " 'heres the official video for our song when the lights die ! we hope you like it <url>\\n',\n",
       " 'can u please ask btr if they already knew their albanian fans ?\\n',\n",
       " 'love you both , but you guys are real jackasses sometimes\\n',\n",
       " 'lmao ! idk fave but i got three shades of red for ya if you wanna freak it out\\n',\n",
       " \"lol he's inlove . ahaha . and you know you like it .\\n\",\n",
       " \"babe is home from work ! time to cuddle & watch ' 30 rock '\\n\",\n",
       " \":p i don't call anybody . some kinda bug with me . btw ritika called today . <user>\\n\",\n",
       " \"don't listen to haters they just bring you down ! pay no mind to the wannabeees i got your back girl ! ! ! snooks for life\\n\",\n",
       " \"doesn't mean you're allowed to use it\\n\",\n",
       " 'i promise with you and god\\n',\n",
       " 'the host of american band stand . he started a lot of careers on his show .\\n',\n",
       " \"yep got them here , cant wait now awww im sure they'll come soon i dont get why they are here already , its far too early x\\n\",\n",
       " 'nicki minaj , starships love that song <3 ( live on <url>\\n',\n",
       " 'i agree with everything you said about sam i just wanted in on the joke daily * hugs * coming your way time to dm ?\\n',\n",
       " \"hell yeah . ! ! ! wish we could hotbox together that'd be cool haha take a coupla hits for me'll do u !\\n\",\n",
       " 'goood keep it free for paddy please xx\\n',\n",
       " \"oh shit that just fucking sucks ! at least we're watching despicable me\\n\",\n",
       " \"i'll be there soon . at least i'll see you at reunion .\\n\",\n",
       " '#1dwebstersurfboards ill join in ! i just need to learn to surf .. xx .\\n',\n",
       " 'now that you left the band , you will continue playing music ? who knows ? ?\\n',\n",
       " '\" avi > > > you look like an anime character or something \" thank you big brother <3 luh yewww hoe !\\n',\n",
       " 'off to seaworld , queensland\\n',\n",
       " 'might get my belly button pierced soon on my birthday yeahhh .\\n',\n",
       " 'it was indeed and hahaha thanks you are joking right ? :p and yeah i should to match ;d\\n',\n",
       " '\" you\\'re beyond that boo . [: \" you are gorgeous\\n',\n",
       " 'night cutie im with you on the head part i never get any after my girl turns in so i feel ya later\\n',\n",
       " 'could i be one of those girls you notice ? been trying ages !\\n',\n",
       " \"with that gorgeous face , i don't know your name , but it ain't important babe cause i'll just call you mine #wale\\n\",\n",
       " 'okay sounds good ! ! text me and let me know ! even if you could come for an hour that would be great to ! just wanna see yah ! !\\n',\n",
       " 'said this song reminds her of me . long time ago , but i still love the song <3 <url>\\n',\n",
       " 'working term time means you get to see trashy daytime tele\\n',\n",
       " \"hahahaha best practice today hahaha love youu you had me literally on the floor laughing today ! i'll see you tomorrow ! !\\n\",\n",
       " 'me too , should be a great day\\n',\n",
       " 'karma will soon find u . play your game well love . good luck .\\n',\n",
       " \"yah ! going to watch tonight ! can't wait\\n\",\n",
       " 'thanks for whut ? ? nuthin , just a little many more inspiration\\n',\n",
       " \"follow me , it'll make me smile\\n\",\n",
       " 'ur not the only 1 dat dey head hangin get it ?\\n',\n",
       " 'haha you should take me with u\\n',\n",
       " 'thank you , i better be on best behavior then look forward to feeding you on friday !\\n',\n",
       " 'new to this follow meee\\n',\n",
       " 'lol u the fam pet\\n',\n",
       " 'it sure is ... however , no , i cannot take credit for that garret , but maybe i will start using some of my own !\\n',\n",
       " \"would i be able to have my ban lifted b / c i didn't do anything wrong ?\\n\",\n",
       " 'time for ... then sleeps ! ! ! #hittheroadjack\\n',\n",
       " 'my head aches when i get hungry . . . )\\n',\n",
       " 'it appears moot as u clearly have started drinking .\\n',\n",
       " \"it's not too late , but thank you\\n\",\n",
       " \"these new songs are sounding killer can't wait for you to all hear them ! awesome stuff coming up ...\\n\",\n",
       " 'i wanna dance on your body the way i shake it on staage\\n',\n",
       " 'right around the corner .. bring me a sammich\\n',\n",
       " 'only 3 weeks left ...\\n',\n",
       " \"oh here it's gonna be a good night yeah gonna go tomorrow and see if i can get one somewhere ..\\n\",\n",
       " 'ether way did u get yo ass beat ? lol bc u my prom date so i might have to hire a hitman hahah\\n',\n",
       " 'rest in peace dick clark , you always made new years a little bit better <3\\n',\n",
       " \"don't underestimate life but take it simply\\n\",\n",
       " 'thanks , but im about to sleep now . kidding ! ) you game for 5am ?\\n',\n",
       " \"film it across canada ! :d especially ottawa with lots of fans ! - p . s . i'd like to audition for the film\\n\",\n",
       " '#mybrother #playipad <url>\\n',\n",
       " \"i'm going to learn a deaf havana song\\n\",\n",
       " \"welp , im not doin ' it . and yes ; we're huge failures #wahh . lol\\n\",\n",
       " 'haha twitter fights are for pussies ! handle that shit ! ! lol\\n',\n",
       " 'me and singing in the car\\n',\n",
       " \"stop perving on their facebook then ! :p haha , jokes ! nooo , she was , she's a mess ! next you'll be saying you love glee ! god\\n\",\n",
       " \"hey gok . what's your fashion inspiration ?\\n\",\n",
       " 'which 1d guy is your perfect match ? mine is liam .. tweet me yours rt please <url>\\n',\n",
       " 'one class today , and spending the morning with my boyfriend > > > #winning .\\n',\n",
       " \"that's the only reason i got in\\n\",\n",
       " \"aw happy birthday lew ! hope you've had a fantastic day , time to grow up now methinks xxx\\n\",\n",
       " 'will be fun\\n',\n",
       " \"what up rage tweet gingey . don't worry be happy / turn that frown upside down\\n\",\n",
       " 'in a user conference ... at work ... all day = boooring ! !\\n',\n",
       " 'ima slide prolly later tonight ...\\n',\n",
       " \"half 5 i will colour it again for you when it's in better condition ! ! ! xx\\n\",\n",
       " 'ion mind tho cuz i live here otl lmao\\n',\n",
       " \"after a tiring day shopping with mom and i'm now preparing my things for the swimming tomorrow .\\n\",\n",
       " 'well i hope you do good on it\\n',\n",
       " 'about to make me something to eat btw the track meet was popping\\n',\n",
       " \"watching tv until i fall asleep , goodnight y'all\\n\",\n",
       " 'good morning ninie . have a nice day . .. segyero !\\n',\n",
       " 'oh i may bring holly up to the game then x\\n',\n",
       " 'i\\'m going to class ! rt \" free headphones outside the commons ! \" . get me some !\\n',\n",
       " \"nah , we're good rt banged out almost 3hours of revision with #kindalethal\\n\",\n",
       " 'thanks love !\\n',\n",
       " 'i wish had a tv show i could watch it all day long ! !\\n',\n",
       " \"i know we do ! ! i love your hair by the way , couldn't stay a normal colour for long could you hehe xxx\\n\",\n",
       " 'is a weirdo\\n',\n",
       " 'yaaa they had boothes down here on \" regents \" day . i have a purple pin on my jacket from them\\n',\n",
       " 'birthday night out / last night with the girls until september at <user>\\n',\n",
       " 'deff agree\\n',\n",
       " 'i love please follow me ?\\n',\n",
       " 'awesome ! thanks for the chegg love have a great day from all of us here <user>\\n',\n",
       " 'got my schedule all figured out .\\n',\n",
       " \"omg i'm so proud of this guy > > > ! ! ! congrats on becoming a theta nu nupe i'm sure you did your thang ! ! !\\n\",\n",
       " '\" \" long day , off to bed . \" night morning \" morning sharon\\n',\n",
       " 'ooo i would get people to follow you but cba right now\\n',\n",
       " 'pandora + pinterest my way to relax !\\n',\n",
       " \"lol . seriously . it's nothing\\n\",\n",
       " 'hello ? ive waited here for you\\n',\n",
       " 'like up b1tch3zz if you want a contest / challenge series ( <url>\\n',\n",
       " 'oh yeah you still talking that shxt ? ? ? hoe\\n',\n",
       " 'the boys are on their way to nz\\n',\n",
       " 'your two biggest fans are and jessica travaglini , you mean the world to them , please show your appreciation x\\n',\n",
       " \"* giggles * you know you done good when you get the block . i'm the owner of a jim utter block\\n\",\n",
       " 'needs to learn how to breath when she sings . i go with <user>\\n',\n",
       " 'my office any time charley\\n',\n",
       " 'tell her i said happy birthday as well ) )\\n',\n",
       " \"lmao , yea ! that's my babyyy what period y'all got together ?\\n\",\n",
       " 'oh yeaah , smell like what ? the dankitydank i just shmoked youu out with ? #fuckswithme\\n',\n",
       " 'lol what you doin for 4/20 ?\\n',\n",
       " 'omg ! thats going to be so cute !\\n',\n",
       " \"the text just sent me ! made me smile she's so sweet ! #loveeeyou\\n\",\n",
       " 'this makes me so happy #ziall <url>\\n',\n",
       " \"rt 9 days left ! tixbox at rkm fe unpad dipatiukur from 11 am - 5 pm and at oz radio bandung 10 am - 4 pm . don't miss it guys\\n\",\n",
       " \"don't forget to send the pictures to me , rachel & madison u\\n\",\n",
       " 'done cut off my nails .. thanks mama for cut it ..\\n',\n",
       " \"not all the year 9 ' s , i've been following you for ages\\n\",\n",
       " 'bby kiss me througt the phone\\n',\n",
       " 'so what we get druuunk .. so what we smoke weeed .. were just having fun .. its .. 444 ... tweeenty ! !\\n',\n",
       " \"niall got braces , can't wait to see him cause he's sucha wee cutey anyway aww one direction ... what am i like . . .\\n\",\n",
       " 'feel free to join hicks , you my nigga too )\\n',\n",
       " '#50liesiwastold - eating crust on bread will make your hair curl ! anyone else heard this ? ridiculous !\\n',\n",
       " 'hope my sister has a wonderful day\\n',\n",
       " 'haha hey there josh could you get that t-shirt down for me ? #no\\n',\n",
       " 'hey i would love to win signed copy of one direction dare to dream #iwantthe1dbook .\\n',\n",
       " \"jaden needs to tweet more i'm desperate ! ! !\\n\",\n",
       " 'i dont live in the uk , the usa , aus or nz . i live in samoa #hamoswant1dtour\\n',\n",
       " \"rt she's got great eyes plus great wardrobe\\n\",\n",
       " \"please follow me and my best friend it's means a lot for us xxx 19\\n\",\n",
       " \"it's about ed drewett and well he still hasn't got the popularity he deserves #asked\\n\",\n",
       " \"that word looks very close to andy biersack's name <url>\\n\",\n",
       " \"hahahah ! ) i-set naten please ! ) let's make paalam to coach marin mahehehehhe ) ) >:d <\\n\",\n",
       " 'why is it i knew you were asian oh yes the pic of you holding your adorable nephew was my clue )\\n',\n",
       " \"awe i'm starting to miss oomf\\n\",\n",
       " \"sam's love for mercedes is so cute ... and creepy . #glee\\n\",\n",
       " 'when boys are special enough to be your first time . ahahahha . on may te ) ) )\\n',\n",
       " 'girls with lip rings , tongue rings , nipple piercings , belly rings > > > #ifindthatattractive\\n',\n",
       " 'you keep them laying around or up your ass ? !\\n',\n",
       " 'congrats : claire , yves and alec are trending now .. ) #pbbteens4\\n',\n",
       " \"' oomf with braces look too good though , . . <user>\\n\",\n",
       " 'i avoid online dating sites . they match you up with people who share your interests and i dont want to go out with a weirdo\\n',\n",
       " 'yaya got the movie tickets for tomorrow night ) ) )\\n',\n",
       " 'are you working today , or are you just responding to tweets ? ? lol ! !\\n',\n",
       " 'okay really tho ... goodnight lol\\n',\n",
       " 'yeah , i should really consider that , probably life would be more interesting .\\n',\n",
       " 'white girlll wasttteddd\\n',\n",
       " 'hehe sorry lauren ! will buy something on ur behalf too x\\n',\n",
       " 'ooo i swear if i get the chance ima )\\n',\n",
       " 'i found the part he sings ! ! ! shoutout to me ? ( live on <url>\\n',\n",
       " 'what a beautiful day for 5 beautiful boys x\\n',\n",
       " \"thanks man i'm actually travelling to exeter to take part at the met office . always wanted to go there !\\n\",\n",
       " \"that'd be too cute to be on the kissing camera at one of the mavs or ranger games\\n\",\n",
       " 'my boo told me he loves me a lil bit today\\n',\n",
       " 'everything will be okay .\\n',\n",
       " \"you're all amazing , too amazing to write a song about\\n\",\n",
       " 'bitches never directly tried me . they know better haha\\n',\n",
       " 'so & i just got finished perfecting our prom moves ! haha #scotlandaintready\\n',\n",
       " 'oh yeah . try not to be jealous of that wild grandpa sweater .\\n',\n",
       " 'rt hei morning be nice day for me today .. have nice day today ... bismillah\\n',\n",
       " \"i know but id much rather save up and go see olly next year than go t4otb there's like noone that interests me atm x x\\n\",\n",
       " \"really tht's nice\\n\",\n",
       " \"they're in 4th & 5th grade & just finished 2 weeks of state testing .. they're pretty much done for the year .\\n\",\n",
       " \"make it through wednesday , then you're halfway !\\n\",\n",
       " 's / o to !\\n',\n",
       " 'you already know doeee\\n',\n",
       " \"sancha's mom wants the deee\\n\",\n",
       " \"only if you'll take my kindle wireless in part exchange ! !\\n\",\n",
       " \"training's done wooo adv . b's so sabaw )\\n\",\n",
       " \"i'm canadian , i always say please and thank you\\n\",\n",
       " 'that was joke btw , clealy loads of people own footballs ha\\n',\n",
       " 'before and after shots maybe\\n',\n",
       " 'urghh , delete your old account then\\n',\n",
       " 'thank fuck for that ! thought i was a good judge ! xx lol\\n',\n",
       " \"#unattractivethingsaboutme that i am a lazy texter but i will only reply to you if u're special to me\\n\",\n",
       " \"this is random , but we haven't talked in forever and i miss youuu\\n\",\n",
       " 'i really wish you looked like that\\n',\n",
       " \"rt if you can't wait for may 6 #goodluckcharlieseason3premiere\\n\",\n",
       " 'that steak - & baked potato is in there calling my name )\\n',\n",
       " \"- . - rt the reactions i'm getting from my last tweet about haitians >\\n\",\n",
       " 'anybody in my followers no anybody that needs a weekend #nanny or an evening #babysitter . #chiswick but willing to travel ? x\\n',\n",
       " 'cancer always have good sex horoscopes\\n',\n",
       " 'you ladies should come work up an appetite with a class before brunch #justsayin\\n',\n",
       " 'made me feel like a punk today lol he pushed me all in my head & face , bet that wont happen again lol\\n',\n",
       " \"first break finally - yosii time ! let's wow our customer\\n\",\n",
       " 'about to upload a picture\\n',\n",
       " \"nah , it's all about cornetto raspberry enigmas <3\\n\",\n",
       " 'uhm no lorans fake noone of the cyrus know her\\n',\n",
       " 'can us have a follow from you ? ! ? ! ) <3\\n',\n",
       " '\" no likes me , no one likes talking to me \" so not true ! ! i lovee you\\n',\n",
       " \"going to bed been a long day ! need my rest o zzz zzz night ' xo\\n\",\n",
       " 'as we go on , we remember . all the times we had together . and as our lives change , come whatever . we will still be , friends forever\\n',\n",
       " 'actually \" catch up lunch \" sounds great .. i hope we catch up some mutual feelings over that tho .. looking straight forward to it ! !\\n',\n",
       " \"what is liam payne's middlename ? xx\\n\",\n",
       " 'has no friends , he reads tho .. <url>\\n',\n",
       " 'try not to do anything to crazy\\n',\n",
       " 'im on my way well in the next hour\\n',\n",
       " 'hon , it sure will \" hehe , we nicheke tu ! ur day will come \" lol ... \" mulika mwizi \" style ... ehe ? ? \" <user>\\n',\n",
       " 'check out the latest photos from our visit to northern england . <url> york is our favorite city so far !\\n',\n",
       " 'mission #getthegoodguy , is now in progress\\n',\n",
       " 'hey have a nice day\\n',\n",
       " 'get the peanut butter or dark choc ones from an american food store , you wont regret it\\n',\n",
       " 'my daughter and team mates are getting ready for a badminton game ! competition is exciting\\n',\n",
       " \"ok , leto - i've been w / u 18yrs ! i've bought your movies / cd's / vyrted my ass off ! think i've earned a call ? do u want blood ? !\\n\",\n",
       " 'no school for me tomorrow or friday yummmp !\\n',\n",
       " '. she think its real this time\\n',\n",
       " '\" oh okay good . u too fly to be depressed \" thanks boo : - *\\n',\n",
       " \"whoa , that's a fine looking pussy !\\n\",\n",
       " \"haha i know but it's the best way to answer the question !\\n\",\n",
       " \"awww don't make me blush x x x it's alright ! keep the icon x x x\\n\",\n",
       " \"greeting from fashionista love , here's the update for today ! enjoy your shopping xoxo , nicole <url>\\n\",\n",
       " \"we'll be up all night !\\n\",\n",
       " 'daddys home its time to play\\n',\n",
       " \"jaja thanks for worry ... u'r a good friend\\n\",\n",
       " 'hey justin bieber can i have follow from you ? love you xoxo\\n',\n",
       " \"you have a good point , thank you you're a monster ?\\n\",\n",
       " 'you can look after it too\\n',\n",
       " 'he is a very big fa kath rt can you follow me pls pls pls , , , imm a bigg fan ! ! ! :d\\n',\n",
       " 'hahahah how ironic . thank you very much\\n',\n",
       " \"heard you're a player ? nice to meet you i'm the coach .\\n\",\n",
       " \"i'll make you a dinner that'll make you stay in the bathroom for a while\\n\",\n",
       " \"- ; bitches ain't shit & they ain't saying nothin : * a ` hunnit mothafuckazz can't tell me nothing \\\\ \\\\ * i beez in trap (\\n\",\n",
       " 'bigger & better things to come\\n',\n",
       " \"and i'm just gonna say , this is great <url>\\n\",\n",
       " '3 of me <url> i love the crosseyed one .\\n',\n",
       " 'nothing i changed my twitcon tho after your constructive criticism , lol\\n',\n",
       " \"rt goodnight to ... i'm so proud of you , you have no cluuue , on one deserves it more then you\\n\",\n",
       " \"ast , come back for more bubblin i'm dublin during the summer ?\\n\",\n",
       " 'do you want to make two #familymenders happy ? then press mine and follow button . we ask very nicely\\n',\n",
       " \"he's worth the wait love propa great shagger\\n\",\n",
       " 'thanks for following your online shopping partner .\\n',\n",
       " 'everyone is entitled to an opinion and i respect that . but , those of you still trashing jeff long can die in a fire . have a good night .\\n',\n",
       " \"wooo 4.20 real pot heads don't wait for a holiday , just saying\\n\",\n",
       " \"i'll be your drunk on a friday night representative\\n\",\n",
       " 'thank you ! ! ! same here !\\n',\n",
       " 'got the new today , love the cover guys x\\n',\n",
       " 'things that people say\\n',\n",
       " ':d :d :d :d :d wish jocelyn had a twitter . #kudos for her too .\\n',\n",
       " 'i think you should tweet this fab doll she honestly loves you sooo much ! please koko ! 1 .\\n',\n",
       " \"hey , can u help my group ? we're doing a video campaign .. we need you to view this link -> <url>\\n\",\n",
       " \"it's so fun ! ! ! go with us soon okay !\\n\",\n",
       " 'yep gonna watch it now\\n',\n",
       " '\" teeth and smile > > #beautiful \" aww your so sweet\\n',\n",
       " '@ thedrybar follow me , please\\n',\n",
       " 'me , liam and harry are following #everyone who follows rt if u did it\\n',\n",
       " \"#aquarians usually isn't tired or lazy . they just like to sleep this describes me perfectly <user>\\n\",\n",
       " 'my favorite thing in the world , is cracking my ankles\\n',\n",
       " 'eating that breakfast , starting a new diet that i learned yesterday !\\n',\n",
       " 'oops i read that wrong )\\n',\n",
       " \"ever looked at your friends & thought , why the heck aren't we comedians yet ? you knowww\\n\",\n",
       " \"cooled it with my bestfriend , i ain't see her in a grip . she been in the cut\\n\",\n",
       " 'lol neither on mine\\n',\n",
       " 'us . look at her lips they blue <url>\\n',\n",
       " 'normal is one of the few terms never used to describe me #imlimitededition\\n',\n",
       " 'really ? i thought you were already in the kitchen ...\\n',\n",
       " \"ok everyone's talking about pbb and we're about fangirling . how's that for making a change ? )\\n\",\n",
       " 'do you enjoy the white small car \" buy by \" albertooo for last chrimas <url> i know i\\'m a believer\\n',\n",
       " \"retweet if you was born in the 90 ' s ! #90's babies\\n\",\n",
       " 'when ike something i remember everything\\n',\n",
       " '#thoughtsduringschool my teacher is so hot ... <user>\\n',\n",
       " 'playing with bella through the door . <url>\\n',\n",
       " 'why fm ? mm diba ?\\n',\n",
       " \"i'm a tshirt hoarder . i love them . but the i won't turn down occasional sweats\\n\",\n",
       " 'she needs to borrow cobeys movies his favorite is depicable me ! i like it too and a part 2 is coming out this summer too !\\n',\n",
       " 'my dinner tho >\\n',\n",
       " 'rt humor : estimating the project size <url> #projectmanagement #joke #consultant\\n',\n",
       " 'play football tonight , up early take my u9 to their match back home out for run , take it from there , maybe sweat a bet in\\n',\n",
       " 'haha hell yeah when ?\\n',\n",
       " 'i have to study now , but please follow me . so i can concentrate ! <3\\n',\n",
       " 'day is going good less than an hr of wk to go\\n',\n",
       " 'listening to a7x and looking at athames online . : <url>\\n',\n",
       " 'of course ! do you have the coffee packed ? <user>\\n',\n",
       " \"ditto . safe travels , love ! rt how are you guys ? i'm thinking about you . hope you all got to smile at least once today\\n\",\n",
       " 'deep rt trying to come down to ur level rt why do u have to be an asshole\\n',\n",
       " \"what's the source of happiness ? or who ... , ?\\n\",\n",
       " 'awhh sucks ! ! ! wanna come home with me and go with me to get my nails done ? ?\\n',\n",
       " '. a . p ni oka oopu opesthunayi gs songs ! epudu review yenti malli.hehehe pepople will laugh at u ! ! hahaha rofl\\n',\n",
       " '23 minute more to fall in love #fridayiminlove <user>\\n',\n",
       " 'haha , he just called me attractive\\n',\n",
       " 'retweet this if you like it , please <url>\\n',\n",
       " 'good for you river , start dropping gold coins in there , dude ! one of your many gay fans <url>\\n',\n",
       " 'i wanna do it in the backseat , you on top of me grinding slowly too the rhythm of the beat\\n',\n",
       " '\" happy #thongthursday tweetybirds <url> yummmy\\n',\n",
       " \"salamat sa updates sec . , you're the best )\\n\",\n",
       " \"who are these new people following me who i don't know .. ?\\n\",\n",
       " 'the next time the boys are in australia niall will be celebrating his 20th birthday ! ( sept . 13th )\\n',\n",
       " \"have an amazing show tonight ! ! i'll be in the audience . hopefully i'll see you afterward sgtc until i die )\\n\",\n",
       " \"i'm glad this day is ending\\n\",\n",
       " \"i swear i'm always retweeting , her tweets are juss too funny or too real\\n\",\n",
       " '- - - the type of girl to change your life\\n',\n",
       " 'queven has the cutest butt\\n',\n",
       " 'amari and ma lil brotha ! <url>\\n',\n",
       " \"beautiful jordan flip flops . they're so small and cute <url>\\n\",\n",
       " 'you can have the one my dog uses .. hahah <url>\\n',\n",
       " 'bwhahahahha you know that was funny\\n',\n",
       " 'job interview though , wish me luck * fingerscrossed * good luck lauri\\n',\n",
       " 'getting a \" hey beautiful \" > > >\\n',\n",
       " \"hi it's my b-day 2day & all i want is 2 get followed by u . x 142\\n\",\n",
       " 'buying a half today ! yay me ! ! !\\n',\n",
       " \"better not make the wrong decision today , or i'll be very upset #reallythough\\n\",\n",
       " \"like what ? rt lmao ! oh don't worry i have ideas ...\\n\",\n",
       " 'everyone follow <user>\\n',\n",
       " \"blerg . 358 this time . i think i need a longer break now . it's hard to get back into the swing of things .\\n\",\n",
       " 'lmmfaoo , i aint think yu was ready for that . bt now that i kno i got chu\\n',\n",
       " 'made thus for you guys and early birthday wishes ! ! )\\n',\n",
       " 'watching never back down in classs\\n',\n",
       " 'you would like it ! the students choose a focal question and research the topic throughout the semester .\\n',\n",
       " \"' turned on webbie radio & & ' whats happenin came on . ayye . ! !\\n\",\n",
       " 'text i just got lol : today is the 7,665 th day of your life , in other words your 21st birthday i ( cont ) <url>\\n',\n",
       " 'he say he will kill somebody ova me !\\n',\n",
       " 'kicks of the day . <url>\\n',\n",
       " 'its the weekend ! ! s coming home anddd s baby shower , exciteddd\\n',\n",
       " 'chelsea played a blinder last night . fingers crossed for the second leg\\n',\n",
       " 'rt shout out to <user>\\n',\n",
       " 'get back up : <url> are you trapped by past failures ? get free with this one #aheartforgod\\n',\n",
       " \"i'm trying to take a nap but i can't while spongbob is on .\\n\",\n",
       " 'have a good time - i know you will\\n',\n",
       " 'until i am in melbourne and available for coffee dates ( or sharing a coke at the mall\\n',\n",
       " 'lol , ima ass whole i like fucking with her scary ass !\\n',\n",
       " \"#youaintnogoodif all you want is to get in my pants . sorrry , but it ain't workin '\\n\",\n",
       " 'i had a boy tell me that the fact that i bump rap & shit all the time was the \" biggest turn on \" he\\'s ever had #rns\\n',\n",
       " 'come to my bed , my house ? xx\\n',\n",
       " 'hey , thanx for following me .\\n',\n",
       " 'when texted me but i was so high and drugged up i spelled shit wrong . she got what i was saying tho lmao\\n',\n",
       " 'hi love your songs good luck with all your future albums .\\n',\n",
       " \"don't you like your kraken cake ? ! this is to celebrate your homecoming ! <url>\\n\",\n",
       " \"she isn't , i am ! she's been served with a workplace asbo ...\\n\",\n",
       " 'ferrari-only highway in malaysia ! thanks to : antype photography : for making us smile <url>\\n',\n",
       " 'sleep well phil rt had a blast tonight with all the musicians on stage with me , hope ( cont ) <url>\\n',\n",
       " 'only 4 more followers until 830 ! please help and spread the love rt\\n',\n",
       " 'thx and * bow * to mrs . australia #ff\\n',\n",
       " '#oomf is actually pretty funny made my night alot better\\n',\n",
       " \"that's exactly y all u guys / girls miss out on sum 1 u could have been with in actually enjoyed be-n with . ... . #advicetewwhoevaneedsit . .\\n\",\n",
       " 'oh , dont get me started trying really hard not to encounter spoilers , felt bad watching the trailer\\n',\n",
       " \"ahh yes why can't the song just bloody happen aha x\\n\",\n",
       " 'nice ! i should prepare my #readathon post hopefully later between dinner and book group\\n',\n",
       " 'sa alesg private or public . ) di ko rin alam bakit 24 instead of 22 eh wala namang event dun ng 22 .\\n',\n",
       " \"anywho morning y'all\\n\",\n",
       " 'girl turn the lights out , i bet i make you tap out !\\n',\n",
       " 'if you hurt me , please know that i always got someone lined up ready to catch me when i fall . im too bad for that #obb\\n',\n",
       " 'if you can ? we have 11 atm so everyone will play hole game x\\n',\n",
       " 'i like him in any hairstyle\\n',\n",
       " '( for women ) ... you know what they say abt big shoes ... big uterus .. uhhh 0_o ? ? ... #somemovie\\n',\n",
       " '#fb girl ! ! hope all is well\\n',\n",
       " 'i love lookn the mirror nd looking good but i neva brag about how i look or what i got #conceited but not to the max like most\\n',\n",
       " 'rt nobody is greater than god ! ! #blessed ) ! ! !\\n',\n",
       " 'tell me why ! hahah .\\n',\n",
       " \"seee i got a problem & i don't know what to do cause ' ...\\n\",\n",
       " 'sooo rt on twitter from my laptop lol\\n',\n",
       " 'it seems to me , or never answered ukrainian ruschers\\n',\n",
       " 'can u please give me the link to 1.2 & 3 ?\\n',\n",
       " 'aww thanks hun . wayyy too nice\\n',\n",
       " 'someone pick me up , and take me to norwich on the 29th , so i can watch lost ! live ?\\n',\n",
       " 'that sucks ! & & good goods just living life day by day ... hby ? ? ?\\n',\n",
       " 'before i met you i never knew what it was like ; to look at someone and smile for no reason\\n',\n",
       " 'everytime i go to the hair salon bat 2aked eny i have a really weird taste in hair oh well\\n',\n",
       " \"yeah for sure man well i think we'll be there a day extra so maybe can sort it then we'll check it sooner to the time\\n\",\n",
       " 'selling a coffee table.tv.couch.bed . need $ 195 by monday lol . #noitsnotfordrugsoranythingbad\\n',\n",
       " \"glad i don't go to freeman , just in case that nerd does blow it up\\n\",\n",
       " 'missing hurry up & get off already ! ! ! lolz\\n',\n",
       " \"it's gonna be a goood weekend\\n\",\n",
       " \"i'm leaving early\\n\",\n",
       " 'better than yesterday ! i can eat and drink now squirrel will be up and well in no time !\\n',\n",
       " 'just tryna text , who can i text on this lovely day\\n',\n",
       " 'nice use of word \" wise act \" ..\\n',\n",
       " 'ah glad to hear it . we must do something soon ! x\\n',\n",
       " 'yeah you should and aha yeahs she was like mmm no not really ahaa :p\\n',\n",
       " \"when you know the width and length and depth and height of jesus ' love , you would not have to worry anymore ! seriously ! it's that great !\\n\",\n",
       " 'hey nialler , can you follow back me ? im so feel lucky if you followed me , please nialler thanks xx\\n',\n",
       " 'i was too high ) ) )\\n',\n",
       " 'is a hot teacher (\\n',\n",
       " '* grinds against you , slowly stripping down * hey baby .\\n',\n",
       " \"i heard you doin you , and you heard i'm doin better\\n\",\n",
       " \"it's actually on itunes now ! u can download it ! ! ask vern or alex alll about it lol = = = > <user>\\n\",\n",
       " 'wearing a dress tomorrow even though i only have 2 classes with him lol\\n',\n",
       " \"guess who's birthday is ... now ? ? ! yours ! #happybirthday #airbag #applebutt\\n\",\n",
       " '#yougetmajorpointsif you rub my back without me asking\\n',\n",
       " 'finishing work early to get my hair done\\n',\n",
       " \"haha okay , that's good\\n\",\n",
       " 'hey there krisbian , follow back ?\\n',\n",
       " 'i hope likes the picture i took on her phone\\n',\n",
       " 'thanks , gary , will follow right back . )\\n',\n",
       " 'what made you wana be in a band ?\\n',\n",
       " 'pretty good , how about you ? xx\\n',\n",
       " 'haha okay what tanning lotion do you use ? i want to get it lol\\n',\n",
       " \"can't wait to go to brick lane next weekend ! spend the rest of my birthday money\\n\",\n",
       " 'tampa bound with da girls\\n',\n",
       " \"i'm gald we dont have school friday now i could sleep longer thursday night or not\\n\",\n",
       " 'thanks and only getting my maths and physics results\\n',\n",
       " 'girl you working wit some ass yea you bea yea make a nigga spend his cash yea his last yea )\\n',\n",
       " 'follow though * desirre * cdfu\\n',\n",
       " \"really ! did not know , cool & i'm watching a movie , eating dinner .\\n\",\n",
       " \"smh not down ! lol and yay inshallah ! that's awesome\\n\",\n",
       " 'late start tomorrow . oh thank god\\n',\n",
       " '#thoughtsduringschool my bed . and a cuddle buddy\\n',\n",
       " 'we sure do ... chicken caesar , feta or meditteranean ?\\n',\n",
       " 'oke thaankss\\n',\n",
       " 'just be safe\\n',\n",
       " ', thinking about cutting everybody off & starting fresh & i know exactly who i want\\n',\n",
       " \"ok so if you're mad at me , please take it out on me rather than on my car #thanks\\n\",\n",
       " 'my subtweets are for whoever they apply to . if you do what i subtweet about then subconsciously im talking to you\\n',\n",
       " \"haha ahww ) good ! i'm excited to see you too ! you know we act like we can only hang at watermelon bust ? #whatupwiththat\\n\",\n",
       " \"blessings from yorkshire pal '\\n\",\n",
       " 'hello i need help in something .. can u follow me back and then unfollow if u want ^ - ^\\n',\n",
       " 'ohhh ohh see if i get a chance to buy a drink later . heh\\n',\n",
       " \"no we'll train him and make his teeth blunt ...\\n\",\n",
       " 'hehe .. yes .. thats true thankyou cc\\n',\n",
       " 'check it out this is me riding the megaramp open last year new stuff for 2012 coming soon <url>\\n',\n",
       " \"i've been alright , hbu ? you go to hueneme right ? : o\\n\",\n",
       " \"we are excited for tonight's press launch for ! ! !\\n\",\n",
       " \"i showed it to mama and she was like oh my gah i'm gonna throw up haha but i think u look pretty sexy haha\\n\",\n",
       " 'obama is a #leo #teamleo\\n',\n",
       " 'good morning how was your show ?\\n',\n",
       " \"lmaoo rt i'll give you greens every time , #soyouknowitsreal\\n\",\n",
       " 'when you gonna go on that diet with me ! follow me ! gracias #newtothis\\n',\n",
       " \"me but i'm going to go due my hair\\n\",\n",
       " 'hi ! thanks for following ! )\\n',\n",
       " 'i love you so much ! can you please follow me ? <3\\n',\n",
       " 'i crackyou up rt lmafoo yoo said the blacker the berry the sweeter the juice & & you know #oomf juice sweet as a bitch ctfuu ! !\\n',\n",
       " 'me and ) ) #statestreetdiner <url>\\n',\n",
       " 'haha thanks gor following ive been wanting to say that .\\n',\n",
       " 'okay , then promote us please\\n',\n",
       " 'made the high school volleyball team\\n',\n",
       " 'thank you bestfriend <3 lol\\n',\n",
       " 'getting sexyy for tonight going out with my girls\\n',\n",
       " 'forever young i want to be , do you really want to live forever ... forever young\\n',\n",
       " 'hell yea can i after movies\\n',\n",
       " 'lol whats good tho\\n',\n",
       " '#iloveitwhen my mom takes me to get a frappe just for no reason\\n',\n",
       " \"they're probably already off .\\n\",\n",
       " 'american pie reunion , gone and cabin in the woods - i wna see them all\\n',\n",
       " 'so right after leaves the first thing says is why am i crying .. haha ( <url>\\n',\n",
       " 'i love being within your presence )\\n',\n",
       " 'i will though i have to so you have nothing to blackmail me with haha\\n',\n",
       " 'i hope blair didnt give you a full blown migraine ... i suggest a bout of dar williams to ease the pain #cantbearblair\\n',\n",
       " 'staying after school with thursday tho\\n',\n",
       " 'woke up to some reggae , classical rock and some new wave ( ahhh ) relaxation #thepolice #bobmarley #thedoors #rollingstones #jimmy cliff\\n',\n",
       " 'i laugh cause idont care anymore\\n',\n",
       " \"i'm about to go to sleep\\n\",\n",
       " 'ga mudheng , just tell u the truth\\n',\n",
       " \"haha , everythime when it's 11:11 i'm wishing that i'll meet one direction someday\\n\",\n",
       " 'i feel more confident with myself\\n',\n",
       " 'uwi ba tayo sheyver ? do come .. kayo ni mama love <user>\\n',\n",
       " 'i have to get tickets this time ! wish me luck ! love youu ! <user>\\n',\n",
       " 'early morning blowing\\n',\n",
       " 'someone tell me why has gone beyond beautiful : s ... ? & can you take ah trip to london soon ?\\n',\n",
       " 'happy 1th monthsary and me love you guys especially anna my babyyy : * *\\n',\n",
       " 'what a beauuutiful day for nyc\\n',\n",
       " 'may napanuodan na po ba kayo ng purple house with eng subs ?\\n',\n",
       " \"would you believe i did eli's pigeon face ? haha . it looks the same , tbh . > ) ) )\\n\",\n",
       " 'ur welcome and no\\n',\n",
       " \"if i'm louder would you see me ? xx\\n\",\n",
       " 'ohhh going to the movies with my big bro tomorrow though\\n',\n",
       " 'maybe after i get back from china !\\n',\n",
       " \"both of y'all can kiss it ! y'all love me , & all the extra ! lolll\\n\",\n",
       " 'i think these pictures i drew deserve a follow <url>\\n',\n",
       " 'shower then text till my eyes close\\n',\n",
       " 'sleepover at mansion with rebecca , and maica\\n',\n",
       " 'mind to follback , tybfr\\n',\n",
       " \"i mean i'm about to go to the store .\\n\",\n",
       " \"everything i look at i see gods loving hands at work . the trees , the stars , all of it man ! it's like the classic tootsie roll commercial\\n\",\n",
       " \"just heard your new single on ! ! sounds fab , really catchy ! it's trending too #callmyname\\n\",\n",
       " \"thank god i don't have any homework ) )\\n\",\n",
       " \"i'm gonna have to try it one day sweet chilli sauce is one of the best !\\n\",\n",
       " 'was it scandalous ?\\n',\n",
       " 'i had just gotten home . tuesday night debauchery with the gays .\\n',\n",
       " 'wow twitter better watch out for people like you hehe\\n',\n",
       " 'lml that too !\\n',\n",
       " 'havin such a good night with the girls ! ! #hannahwaite #chanicekett #anniemurdoch #lucyyoung\\n',\n",
       " 'cause you were flllyyinnnggg ... and it was bumpy so i was like k .. lmfao but whatever i got over it !\\n',\n",
       " 'do it ! ! will be so so good ! once in a lifetime\\n',\n",
       " \"hmm that's cute .. my watch is being passed around des moines and posted on facebook\\n\",\n",
       " \"it's #boythudervisitsgyss visits ! ! trend it now !\\n\",\n",
       " 'thanks ! what do you use snagit for ?\\n',\n",
       " 'i love the video #boyfriend , i love , always stay strong and never say never justin te amo 28\\n',\n",
       " \"i suck at all the languages except for my own ! ahahaha i hope i'll learn some more one day . be a little more like you ...\\n\",\n",
       " 'rt \" thanx a lot \"\\n',\n",
       " 'ok gonna play a few throw backs while i have my midnight snack slave - just a touch of love : <url> via <user>\\n',\n",
       " 'you should do another twitcam soon !\\n',\n",
       " 'keep that hashtag together #rookiemistakes\\n',\n",
       " \"you can go volunteer as tribute , i'll stay home with gale\\n\",\n",
       " 'haha i know ! ! ! someone showed me that too\\n',\n",
       " \"just read something , and i've realised .. you know nothing ;] if confused text me baaahaaa ! i love you xxx\\n\",\n",
       " 'you are off to a roaring start !\\n',\n",
       " \"i'm sorely tempted to add owls in my room too\\n\",\n",
       " \"he kno it be a wrap when i'm riding it from the back\\n\",\n",
       " 'no fcat for me today thank god\\n',\n",
       " 'spent time with arlene\\n',\n",
       " 'omg ! ! ! just did mi hair ! ! ! im amazing ! ! : oxoxox to mi followers ! ! ! muaaa\\n',\n",
       " \"twanna hear a poem ? okay .. roses are red , violets are blue , you don't suck dick .. then bitch fuck you\\n\",\n",
       " 'hahaa thought youd be pleased . xxx\\n',\n",
       " 'remember to have your taxes in by midnight tonight ! ! !\\n',\n",
       " 'is one of the reasons i go on youtube and then to watch <user>\\n',\n",
       " \"rt good morning i don't wanna forget the presence is a gift so i say thank you\\n\",\n",
       " \"whatever time , i'm not bothered . i should be up\\n\",\n",
       " 'lol #knowthat\\n',\n",
       " 'spent #earthday in the mountains smoking my favorite plant with my bros . happy #420 , #stonernation .\\n',\n",
       " 'where can i sign up to be in your music videos .. i will do it for free haha xx\\n',\n",
       " \"ekk i'm excited too ! your going up saturday right ? !\\n\",\n",
       " 'how about them braves tonight ! 9-3 over the mets ! haaa !\\n',\n",
       " \"can't wait till one direction's concert next year ! bring on 2013 !\\n\",\n",
       " 'i love so much ! <3 i wanna start talking to her a lot more like i used too )\\n',\n",
       " '+ + breakfast = great start to the day\\n',\n",
       " 'taco bell for the second time today\\n',\n",
       " 'at least i got to skip my ugly classes today\\n',\n",
       " \"i'm good what about you ? ? ... omg i know . great to have on twitter as well xoxo\\n\",\n",
       " \"it's official ! ms . jean garcia promotes this twitter page . pls help us too to promote this . thanks ! <url>\\n\",\n",
       " 'oh whoops . flight is here . sorry thanks for being so cheap . you do that well\\n',\n",
       " '. follow them and gain\\n',\n",
       " 'anytime . us girls have to stick together\\n',\n",
       " \"- thx , and want you to know , i've bought your tunes on itunes .\\n\",\n",
       " 'oh well , everyone has different opinions .\\n',\n",
       " 'today when i am back home i went to see a year one direction in the making harry dont listen it . you have a fantastic voice\\n',\n",
       " 'getting our nails did with <user>\\n',\n",
       " \"i want guy that's from philly ha !\\n\",\n",
       " 'made me laugh . i must be a teacher .\\n',\n",
       " \"ohhh right right ! hahaha yes i can't wait for this xmas ! i know what to send everyone now )\\n\",\n",
       " \"5 ' 5 with brown eyes , a smile like the sunshineee\\n\",\n",
       " 'hmm i have to say i miss you bunches ! #iloveyouu and def cant wait to see you tonight #mytime\\n',\n",
       " \"you'll get the hang of it ! !\\n\",\n",
       " 'buat cewe 2 .. find the love who would fight for you and ur relationship . and when u find that person , fight for him . never give up\\n',\n",
       " '<url> even though justin has been to wales once before ( he was in bangor ) can you please help and sign this <3 thanks\\n',\n",
       " 'rt the heat game is on and you lookin for a twitter wifey ? rt who wants to be my twitter wifey \"\\n',\n",
       " 'thats crazy ! and yes we do and ill see if i cab find anything .\\n',\n",
       " 'i want to curl up in a ball and sleep forever .\\n',\n",
       " \"been writing songs like it's my job , but i have to admit , i don't think i can wait anymore . i want people to hear them .\\n\",\n",
       " 'cool , hopefully before my hol late august ... some new material to relax to on the beach\\n',\n",
       " '\" smh up nepa ! ! ! * looks around * erm ... oh ! electricity is bak :d \"\\n',\n",
       " 'thankyou whats a reserve and b reserve ?\\n',\n",
       " 'so nice walking into fye yesterday an asking for the cd\\n',\n",
       " \"you're a thuggg ! why you playin ? lol & i believe it , you seem too mean to approach .\\n\",\n",
       " \"hello miss cheryl come and get me . . . oh , sorry jen it's you . . . #tweetinglyricslykagangsta xxx\\n\",\n",
       " 'getting my first voxbox ! ! ! ( its a box of free make-up and goodies you are sent to review lol ) yayyy !\\n',\n",
       " 'these girls get mad cause i never want something serious i just think about you cause you made me not want to go back to that . heartless\\n',\n",
       " 'shut up & just make sure my bae be careful\\n',\n",
       " 'a couple more hours and we willl be workin on our seeexxy ass tan lines #cantwait oh yeah #its420 #yay\\n',\n",
       " 'this is a great day ! #finallyyouadmitit\\n',\n",
       " \"tml going ikea shop for racks plus i'm going to look for some decor or furnitures\\n\",\n",
       " 'kiss you on your neck and tell you everything is great\\n',\n",
       " 'no bother , youll get the grades x\\n',\n",
       " 'haha ... mornin though rt bana ! sijazoea android bado #teamdabr\\n',\n",
       " 'please follow me ! i have been trying for so long\\n',\n",
       " 'continue going with him , being his little dog and following him everywhere yeah ?\\n',\n",
       " 'yes im abt to b a mommy ...\\n',\n",
       " 'lol how many tennis courts do you need ?\\n',\n",
       " 'i was so close to tweeting that ... glad i didnt now\\n',\n",
       " \"i'd go to the doctor for that cough , mate\\n\",\n",
       " \"you are strong and you don't let other people influence you or get you down\\n\",\n",
       " 'i forgive you this time but never again and ye\\n',\n",
       " 'anytimeee #bfftweet\\n',\n",
       " \"download #hookt it's a better way for us to message one another <url> my hookt id is dmy 3bp3\\n\",\n",
       " 'oh 2nd semester . ^ ^ first year in the university .\\n',\n",
       " \"oh good cos i've run out of bread ! !\\n\",\n",
       " \"he's a father-like hyung .. i like being around him .. i learn many things from him\\n\",\n",
       " \"dont complain , only action you'll get for a while\\n\",\n",
       " 'i love to see you jealous\\n',\n",
       " 'one of our teams got 2nd place in mud tug ! ! congrats ladies !\\n',\n",
       " 'hey ! stranger over there im really liking the way , you whip it whip it ! i really want you now your so fine so fine\\n',\n",
       " 'definitely i love going to the echo to see shows !\\n',\n",
       " 'playing with my new watercolor paint pens <url>\\n',\n",
       " 'when we all know that misses mr w\\n',\n",
       " 'her daily sentence : \" i hate my french teacher . \" lmao <3\\n',\n",
       " 'congrats on the prevailing of common sense\\n',\n",
       " 'thanks & i tried my hardest . but she pushed me .. lol thts old shit tho , im over it\\n',\n",
       " \"ok ! i'm starting to love one direction .\\n\",\n",
       " 'i cant sleep much cuz i must get up at 6.30 am everyday when i have school : l ... have fun ther and say them hi from germany\\n',\n",
       " 'it will grow one day\\n',\n",
       " \"ik u wont see this tweet but i always tweet you everyday hoping you'll replay ! my bday is in a week ! happy bday to me ?\\n\",\n",
       " '#youcangetmajorpointsif you send me random cute texts that will keep me smiling all day long\\n',\n",
       " 'tried to do the #philippines #flag . #nails #yellow #red #blue #hard #candy #filipino #pinay <url>\\n',\n",
       " 'had a good nap probably finna go bk to sleep\\n',\n",
       " 'you should watch this korean pop group ! they are really something ! <url>\\n',\n",
       " 'i think all of them have boyfriends too ... buhahaha . true that though\\n',\n",
       " 'now nah udh liat kan aku senyum :d rt \" when i see you smileee ... ~ ~ \\\\ m / \"\\n',\n",
       " \"maybe . but you just see 1 of the ' dot ' and you see 1000 of bp .\\n\",\n",
       " \"for sure ! can't wait for tomorrow !\\n\",\n",
       " 'nice haha ! have fun ! and i did and thank you ! !\\n',\n",
       " 'it did as it goes !\\n',\n",
       " \"let's just hope they taste good\\n\",\n",
       " 'awww ! so jealous right now ! haha ! what was it / she like ? ? hehe ! xxx\\n',\n",
       " 'i want to come back alreadyyy\\n',\n",
       " \"tom has blue eyes , katie has brown eyes , and suri was lucky enough to get her dad's same amazing eyes\\n\",\n",
       " 'we have a brother sister gang , and we intend on bullying our mom xd\\n',\n",
       " 'pshh u better and aw man i want my clam cakes\\n',\n",
       " \"and they've got cocktails to start they know us well #nabshow <user>\\n\",\n",
       " 'lol i was too ! shakinq , heart beatinq fast and all ! but it ainn baddd\\n',\n",
       " \"yes that's right so that's not too long to wait !\\n\",\n",
       " 'hey ! take me and steph out for a raspado ! ! ! haha\\n',\n",
       " \"i wouldn't hate luc if he leaked a sex tape xp ) imagine ... me too : 333\\n\",\n",
       " 'tweetiung from the harmonys ( lol\\n',\n",
       " '\" #mybiggestfearis losing my bestfriend we\\'ve lasted this long . this is forever\\n',\n",
       " 'was amaziiing ! his arms corrr sexaaay\\n',\n",
       " 'naaah , \" je vous aime \" is . ich habe euch lieb . is that right ?\\n',\n",
       " 'well jst the tweetn n the dark part\\n',\n",
       " \"dear anyone who's reading this . i hope you have a reason to smile today . #behappy\\n\",\n",
       " '10 minutes left to join the networking cruise ... its rockin\\n',\n",
       " 'good yeah all good thanks darling . yeah definitely , lemme know when your free and we will all have a catch up\\n',\n",
       " 'i have to many socks to chose from for wacky tack day ! which one should i wear ? #coolsocks <url>\\n',\n",
       " '#startyourdaywithasmile ) ) )\\n',\n",
       " 'me , diamond , michala , nd raced to 3rd hr we wass fooling !\\n',\n",
       " 'niggas be thinking they doing something by unfollowing you .. you just doing me a favor thanks ! !\\n',\n",
       " 'when people swear they know you . no uu know what ii want uu to know\\n',\n",
       " '#thoughtsduringschool i wish a was a hamster so i could just chill all day .. i wonder what its like to be a hamster ... must be cool\\n',\n",
       " 'i heard in the streets im the one you wantin\\n',\n",
       " 'when you just sit there and randomly laugh about something that happened\\n',\n",
       " \"wha ? ? ? pshhh pls you ain't bout that life\\n\",\n",
       " '\" would you mind \" hmmm\\n',\n",
       " 'ahhh , this is gunna be a good one\\n',\n",
       " 'oh thank youuu ! it took awhile to figure it out .\\n',\n",
       " 'thank you , i was very happy !\\n',\n",
       " 'it would be the proudest moment in my life\\n',\n",
       " 'pmsl na u go girl was a good game hun stop with them rolly pollys init lool x x\\n',\n",
       " 'got my call today need to finish this letter ! !\\n',\n",
       " \"i think you're both probably right , but i had to point out the counter-example because i'm a dick like that\\n\",\n",
       " \"nice one mate , i'll make sure to pop in for a pint when i'm in town then\\n\",\n",
       " 'maybe a hot shower will get me tired ?\\n',\n",
       " 'rt <url> the review check it out - - - jheeeze bars cuzzy * salute * ima send you that track on sunday\\n',\n",
       " 'louis bunjee jumping in nz ! ( credits to the owner ) - marie xx <url>\\n',\n",
       " 'it looks so good ! and josh is in it which automatically makes it amazing x\\n',\n",
       " '#primaryschoolmemories you cutting your ear open with a pair of scissors\\n',\n",
       " 'save a horse ride my scooter .. ladies any takers ?\\n',\n",
       " \"liam got rt'ed from some eggs hi to you eggs . <url>\\n\",\n",
       " \"ok ! so i started thinkin ' about what to getcha for ur birthday & i have come to the conclusion that i am a fucking genius ! !\\n\",\n",
       " 'sooner or later things will be the way you imagine them .\\n',\n",
       " 'k , thats better ! yah i will\\n',\n",
       " 'hi chachi ! keep safe . please follow back\\n',\n",
       " \"y'all should make a road trip & come get me on friday so i can join !\\n\",\n",
       " \"you'll be on the train home ... remember !\\n\",\n",
       " 'forever with you no matter what\\n',\n",
       " 'thank you boo , and love you too ... )\\n',\n",
       " 'thankyooou tooony i loooveyoou soosooo much !\\n',\n",
       " 'uhmm i guess ill go out for a drive #letshopeforthebest\\n',\n",
       " 'anything for my zebby poo ! ! !\\n',\n",
       " 'being drunk is so much better than not being drunk\\n',\n",
       " 'goodnight to my baby hope she had a wonderful day ! <3\\n',\n",
       " 'i just got home . goodnyt . opening naman bi tom so i need to rest na .\\n',\n",
       " 'lol yeah my old ish was getting old and this how i be feeling so why not\\n',\n",
       " \"s / o to girls who don't allow their hearts to be broken\\n\",\n",
       " 'sending this out 2morrow <url>\\n',\n",
       " 'hahahah you should have heard her yesterday ! she told me to sign up for christian mingle ...\\n',\n",
       " 'baby i got nothing to hide <user>\\n',\n",
       " 'just out enjoying some sun <url>\\n',\n",
       " 'looking at old pics of me & all i see is fayfe #cray <url>\\n',\n",
       " 'hey can you do me a huge favor and check out my friends song . maybe subscribe ? ) <url>\\n',\n",
       " 'thanks for the mention ! prolificwriters <url> much appreciated ! #jenny_meszaros\\n',\n",
       " 'man , it was a looonnng night ! ! part 2 next weekend\\n',\n",
       " 'still so fucking orange from last night . i look ridiculous < max faggot warehouse tomo ? poom poom flex\\n',\n",
       " 'hey gorgeous ! lol\\n',\n",
       " 'in thee bed looking at keepers creepers , with a bra & & leggings on eating animal crackers\\n',\n",
       " \"sure ! ! ! omg ! ! i can't wait ! ! so excitated ! ! #boyfriend ! when my idol follow me ? 18\\n\",\n",
       " \"rt rt rt rt #openfollow for kpopers ' all fandom ' flwrs kece * b :d openfollow\\n\",\n",
       " 'i could understand your comment with google translate , thanks a lot and it was a very happy time for me to see you all in seoul\\n',\n",
       " 'i\\'ll just have to wait for \" the payback years \"\\n',\n",
       " \"any advice ? it's my first time going !\\n\",\n",
       " 'now im on the phone with makeda i missed them !\\n',\n",
       " 'alright alright . time to close the laptop . goodnight nigguhs <3\\n',\n",
       " \"it's happy hour ... all day ... at sonic . i'm not complaining .. best day ever ? yeah . best start to my week of finals ? yesss ! ! !\\n\",\n",
       " 'but then robinho took his spot & doubled that with an amazing 40 + goal tally\\n',\n",
       " 'got some more snacks for my baby today . love you <3\\n',\n",
       " 'good morning ! ! thanks have a blessed weekend !\\n',\n",
       " \"i'm notorious for doing shit like this for trending topics :d #noproblem\\n\",\n",
       " '\" babe came over to comfort me she cute huh <url> ctfuuu\\n',\n",
       " 'thanks for the info\\n',\n",
       " 'just told my mommy how much i love and care for her\\n',\n",
       " \"even tho u wont see this .. im home sick , but other than that i'm great ! how are you today ? ur the sweetest btw ! much love !\\n\",\n",
       " 'my dad is always right #heknowsbest ! ! #ilovemydaddy #ourrelationship ! !\\n',\n",
       " 'nothing wrong . entirely a personal choice\\n',\n",
       " 'everyone follow she is really nice and has good chat\\n',\n",
       " 'hii ed come to australia <3 xx\\n',\n",
       " \"gratz's powerpoints + the stuff i actually understood in hilliard's class = an outstanding essay\\n\",\n",
       " \"#yougetmajorpointsif you're not too sappy ... ew ... even though says i'll die alone hahah\\n\",\n",
       " \"who's this hottie ? ? ) <url>\\n\",\n",
       " 'awwwe okay babyy byeee :\\') goodnight , sleep well , and sweet dreams \" dream about me and juju \" gonna miss yew more <3\\n',\n",
       " \"it seems too good to be true , but i don't want to wake up out of it .\\n\",\n",
       " 'echo cd is on repeat right now ! i love every song & voices of & <user>\\n',\n",
       " 'yeah just days before confi and you decide to cut ..\\n',\n",
       " 'you can get like norwich-london on the train for 8.50 depending on the date !\\n',\n",
       " 'we on the phone now\\n',\n",
       " 'lol okay thanks tyson\\n',\n",
       " 'well , thank you for the visit , glad you enjoyed\\n',\n",
       " 'size small please\\n',\n",
       " \"lovin ' my pics a little too much ! hahaha oh well ! <url>\\n\",\n",
       " 'waking up to the sound of birds chirping\\n',\n",
       " 'today was fkin dope . i was chef for the whole class leading niggas & telling em what to do .\\n',\n",
       " 'rt words of an adulterer ! lolrt baby u re finer than ur fine cousin ...\\n',\n",
       " '.. well , the sky is blue today ! .\\n',\n",
       " 'caught me chilln on skype this morning . good morning world <url>\\n',\n",
       " 'hi thank you very much for the rt !\\n',\n",
       " 'seriously what time though ? haha love you dude . turn that frown upside down x\\n',\n",
       " 'i saw your cute little face in the stands\\n',\n",
       " 'believe it boo ! what happened today was amazing ! and now we are seeing them in a few short hours xoxox\\n',\n",
       " \"lool dw they're nothing ignore my twitter complaints haha if they get worse i'll go doctors\\n\",\n",
       " 'yap , team from indonesia\\n',\n",
       " 'morning charlotte , you are up early . have a great day i am off playing golf later !\\n',\n",
       " \"i don't mind who's getting it\\n\",\n",
       " \"all the recent photo shoots i have had are now online at <url> - check ' em out ! <url>\\n\",\n",
       " '\" what\\'s up with you \" i really been busy , just trying to do the right thing\\n',\n",
       " 'do you like harry potter ? and hunger games ?\\n',\n",
       " 'thanks for the history thingy\\n',\n",
       " 'i should be mad , but for some reason im not\\n',\n",
       " 'a bit of both an erstwhile sports journalist !\\n',\n",
       " \"haha not for me ! and yeaaa ! ! ! and meh it's going good i guess getting amazing marks and shiz lol\\n\",\n",
       " \"im not proud to say this but please stop poisoning other people's mind . stop feeding them with your insecurities . stop it . stop it . night !\\n\",\n",
       " 'looking mighty fine in your new twitter icon ! x\\n',\n",
       " \"most economists agree that higher vat's r the way to go ( hst / gst 4 us ) , but try selling that to the double-double masses !\\n\",\n",
       " 'i love the bethlehem store\\n',\n",
       " 'i have to be honest , i could listen to them\\n',\n",
       " 'they will trust xxx\\n',\n",
       " 'good to know <3\\n',\n",
       " \"i know ! :/ hey did you know that demi is coming here ! she'll play in argentina !\\n\",\n",
       " \"it's my birthday in 14 days could i please get that follow from you as a gift ? <3 <3\\n\",\n",
       " 'did the bookbagboys win ?\\n',\n",
       " 'hi , can you follow me on please please , . kisses from france x3 2032112 2\\n',\n",
       " 'i finally get to see poetic justice , all at one time not just parts of it\\n',\n",
       " 'i can be the sweetest girl you have ever met , but when you get on my bad side all hell breaks loose\\n',\n",
       " 'good night to our lovliest hero xx\\n',\n",
       " \"i'm staying single for a while i need to focus on me instead of girls ! ! but i'm still gonna have fun #singlelife going ok for now\\n\",\n",
       " 'thanks for the rt entrenovias\\n',\n",
       " 'happy happy birthday to yer lovely brotha !\\n',\n",
       " 'rt getting gassed to in my tech class , my teacher is like wtf lool posh prick ! !\\n',\n",
       " \"wow , i actually think it's awesome !\\n\",\n",
       " 'hey there ! ! !\\n',\n",
       " \"shoutout to she's a directioner and follows back\\n\",\n",
       " 'lol . do you work tomorrow ? better get to bed woman !\\n',\n",
       " 'hahah ! only chayton would\\n',\n",
       " 'really ? lolol sounds like a top lad\\n',\n",
       " 'courteous of my lovely friend knows what to do when a girl feels down <url>\\n',\n",
       " \"mexico is now very late , so i'll go to sleep , i hope to hear from you when you wake up , wish me good night\\n\",\n",
       " 'the biggest day hye sweetheart <user>\\n',\n",
       " 'dont worry , we wont tell anyone ! our little secret ( live on <url>\\n',\n",
       " 'oh hahha yes must bond my classmates were bonded through orientation so we got very close hahha somehow jiayou ! ^ ^\\n',\n",
       " 'thanks #twitneighbours #ff\\n',\n",
       " 'to right mark well said dude\\n',\n",
       " 'i think those of us that work there would beg to differ hahah .\\n',\n",
       " \"god is good all the time . he's there for you in good times and he also stays with you during your bad times . ) )\\n\",\n",
       " 'its gonna be a good weekend\\n',\n",
       " ', now following back bestfriend ! )\\n',\n",
       " \"alrighttt whale wanker :p glad we didn't go jogging haha ! xx\\n\",\n",
       " 'lolol when people sub-tweet me youre cute af\\n',\n",
       " 'and star power rt kush & orange juice and burn after rolling are my favorite wiz khalifa mixtapes\\n',\n",
       " 'thank you ! i love you more <3 and my ppl love u too\\n',\n",
       " 'do i want it in the kitchen ? isaid hell yeah\\n',\n",
       " 'wanna meet me half way later bitch so i can have my jeans back ? ) )\\n',\n",
       " \"#bbcfootball feelings are chelsea are going through but don't know how ! ! !\\n\",\n",
       " 'thankss for the shoutout\\n',\n",
       " 'the scent of freshly cut grass\\n',\n",
       " \"never slow cooked pork chops before . i have done them over low heat on the skillet . crockpot i've done shoulder and butt\\n\",\n",
       " 'look up quotes on google\\n',\n",
       " 'the older i get , the more i see the power of that young woman , my mother\\n',\n",
       " 'aw the smiths on at work . very unexpected surprise\\n',\n",
       " \"oh right i see :') what time will it be ? like english time ? xo\\n\",\n",
       " 'that a boy . next time you come we will plan something excellent and will hold you to that .\\n',\n",
       " 'shhhshhsshhhshut the fuck up\\n',\n",
       " 'thanks for the follow you guys sound amazing\\n',\n",
       " 'when my headphones are on , i am in my own dream world .\\n',\n",
       " 'it just makes me feel like my efforts to overcome difficult situations arent wasted when people can see the difference .\\n',\n",
       " 'oh of course lol #ourwholeuniversewasinahotdensestate\\n',\n",
       " 'ctfuu , you coulda said that :p & tell her i said hi\\n',\n",
       " 'my phone never notified me of your reply ! aw thank you i can defo come now , woop , see you at 8 x\\n',\n",
       " 'lantaran to si kar eh . di na kita gusto eh . actually , mahal na kita eh : \" > ) ) )\\n',\n",
       " 'totally agreed viv\\n',\n",
       " 'yahhh thank you ) night , see in the am .\\n',\n",
       " \"you're just as in love with the hunger games as i am at the moment , it seems . love that .\\n\",\n",
       " \"could i ask that you follow me ? i'd like to send you a couple of dm's . many thanks\\n\",\n",
       " 'chillin with matt and brittany stay strong <3\\n',\n",
       " 'either is soo cute\\n',\n",
       " 'yay my bestie i havent seen in 2 years coming to see me today\\n',\n",
       " \"when will ftsk be announced for warped tour 2012 ? lol i'm seriously hoping you guys will be there xxx\\n\",\n",
       " 'nf my brother gf follow back\\n',\n",
       " \"g'night then\\n\",\n",
       " 'ready to start cosmo !\\n',\n",
       " \"i told my mum it's a pug or a baby - shes warming to the idea\\n\",\n",
       " \"no i haven't spent it , still got 120 but i'm planning on spending it hehe\\n\",\n",
       " 'i actually like being single , it means that #ridingsolo can be my theme song ) #myjam\\n',\n",
       " 'but then again , its unique\\n',\n",
       " 'these are on sale for $ 10.00 ! amazing ! <url> seriously go look at their sale section . #loveshoes <url>\\n',\n",
       " '16 days and no selfharm\\n',\n",
       " 'we have the same birthday only that i was born a few years after you ! sorry for that\\n',\n",
       " 'mrs yoder told my mom after skool was too late to go ? so i have to go in the morning which is stupiddd but i am gonna pass\\n',\n",
       " \"guess i'm watching movies tonight . anyone wanna join ? haha\\n\",\n",
       " 'defiantly love waking up and reimi being here\\n',\n",
       " 'if you looking for me you know where to find me ,\\n',\n",
       " 'small big boobed blonde seeks danny ( the script ) look alike lmao xx\\n',\n",
       " 'lol ! and when we decided to sing somebody that i used to know in the middle of adventure island like cool kids\\n',\n",
       " 'people gonna judge im sure but it me and you babe .\\n',\n",
       " 'i wish you would ! lol , then i could return the favor ! )\\n',\n",
       " 'challenge accepted ! ! lol\\n',\n",
       " '\" that\\'s good ( keep ya head up & stay beautiful ! \" : )\\n',\n",
       " 'you guys did an amazing job ! really really great .\\n',\n",
       " 'the mood is set . my body is screaming out for ya . i gotta secret i wanna show ya #noholdingbackk dont stop , dont you dare .\\n',\n",
       " 'whoaaa whoa whoaaa sweet child of mineee yeahhh yeah yeahhh #stepbrothers\\n',\n",
       " 'what an amazing performance to end you 18th year with , you rocked\\n',\n",
       " 'good luck kak \" believe in allah that everything would be okay \"\\n',\n",
       " \"it's nice to be creeped upon ! !\\n\",\n",
       " 'if u me follow me and i follow back that doesnt mean unfollow me so you have 1 more follower . i will just find u and unfollow right back\\n',\n",
       " 'when im home bored i watch cooking channels . wishing that can be me cooking all that food .\\n',\n",
       " 'just rescued a fox with a broken leg\\n',\n",
       " \"lol u know u can kick that person off of chat on blogtv right ? lol i'm watching ur blogtv right now . u should follow me (\\n\",\n",
       " \"i've got presents for everyone from my event ( beware they are shit ) haha #loveyou\\n\",\n",
       " 'so its working out fine ! nice so much wish i was there , but i do believe it will be more opportunities ! good luck\\n',\n",
       " 'im proud ta say that my big susta gone make it in this world .. a nigga bouta graduate ... i love her\\n',\n",
       " 'they are sold out , but if u have extra then feel free to send 2 this way .. you might know people that can make it happen\\n',\n",
       " 'i wanna love u , every day and every night !\\n',\n",
       " \"relax ... rt i just don't want to start naming names , unless provoked .\\n\",\n",
       " 'thanks to my pin up studio team yesterday , we did some great pictures ! <url>\\n',\n",
       " 'bitch ishould of had myguards up like you did . but itsss cooo . illl comeback\\n',\n",
       " 'awww #goodnightbabylux and #harrylovesbabylux are trending\\n',\n",
       " 'my booo > rt you my everything\\n',\n",
       " 'one more follower please ? #teamfollowback\\n',\n",
       " 'vas happenin boys ? rt if you remember this <url>\\n',\n",
       " \"i can not wait for esque june 19 i'm very anxious te amo 28\\n\",\n",
       " 'finished ! this pouch is on its way to new york today ! time to wrap it up ! <url>\\n',\n",
       " 'things that turn me on ... male gleeks * cough <3\\n',\n",
       " 'can you give me a shoutout i have followed\\n',\n",
       " '* talks in ear peice * kevae & toolay pat his ass down on da low\\n',\n",
       " \"aw , can you ask her to follow me ? haha , been trying for a long time ! she's an inspiration . have fun you two ! xx\\n\",\n",
       " 'happy birthday ... from all slater fans ... ) )\\n',\n",
       " 'all true except the nice , smart , handsome part .. ! thanks my love .. !\\n',\n",
       " 'ayeee so proud of you\\n',\n",
       " ...]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i dunno justin read my mention or not . only justin and god knows about that , but i hope you will follow me #believe 15\n",
      "\n",
      "dunno justin read mention . justin god knows , hope follow # believe 15\n"
     ]
    }
   ],
   "source": [
    "print(tt)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(tt)\n",
    "result = [i for i in tokens if not i in stop_words]\n",
    "result = ' '.join(result)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.686, 'pos': 0.314, 'compound': 0.4939}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores('just woke up , finna go to church ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/etienne/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987aadacba074df29955d5d9e3a82f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_2 = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for tweet in tqdm(tweets):\n",
    "    tokens = word_tokenize(tweet)\n",
    "    result = [i for i in tokens if not i in stop_words]\n",
    "    result = ' '.join(result)\n",
    "\n",
    "    ss = sid.polarity_scores(tweet)\n",
    "    if ss['neu'] == 1:\n",
    "        prediction_2.append(-1)\n",
    "    elif ss['neg'] > ss['pos']:\n",
    "        prediction_2.append(-1)\n",
    "    else:\n",
    "        prediction_2.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import SpatialDropout1D\n",
    "\n",
    "from keras_preprocessing import text\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import gensim\n",
    "import logging\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pd.read_csv(\"Datasets/twitter-datasets/train_pos_cleaned.csv\", index_col=0)\n",
    "neg_df = pd.read_csv(\"Datasets/twitter-datasets/train_neg_cleaned.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([pos_df,neg_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49673</th>\n",
       "      <td>k fine lah if liddat i also sleep loh haiz nights twitter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71551</th>\n",
       "      <td>going to be told im blind tomorrow ok slight exaggeration but yeah having my eyes tested then a day of uni work just need it done</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5506</th>\n",
       "      <td>sometimes its nice to just buy a little bit of jewelry #liasophia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38370</th>\n",
       "      <td>this is my tweet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36930</th>\n",
       "      <td>im not always nice but i dont have a reason not to be</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                  tweets  \\\n",
       "49673  k fine lah if liddat i also sleep loh haiz nights twitter                                                                           \n",
       "71551  going to be told im blind tomorrow ok slight exaggeration but yeah having my eyes tested then a day of uni work just need it done   \n",
       "5506   sometimes its nice to just buy a little bit of jewelry #liasophia                                                                   \n",
       "38370  this is my tweet                                                                                                                    \n",
       "36930  im not always nice but i dont have a reason not to be                                                                               \n",
       "\n",
       "       label  \n",
       "49673  1      \n",
       "71551  0      \n",
       "5506   1      \n",
       "38370  1      \n",
       "36930  1      "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sample(frac=1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"Datasets/twitter-datasets/test_data_cleaned.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100260 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 100000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 300\n",
    "tokenizer = text.Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(np.hstack((train.tweets.values,test.tweets.values)))\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (199976, 50)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(train.tweets.values)\n",
    "X = sequence.pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159980, 50) (159980,)\n",
      "(39996, 50) (39996,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 1)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/etienne/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159980 samples, validate on 39996 samples\n",
      "Epoch 1/3\n",
      "159980/159980 [==============================] - 555s 3ms/step - loss: 0.4655 - accuracy: 0.7685 - val_loss: 0.3971 - val_accuracy: 0.8163\n",
      "Epoch 2/3\n",
      " 99328/159980 [=================>............] - ETA: 3:11 - loss: 0.3412 - accuracy: 0.8485"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6a19b2aa3017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m           validation_data=(X_test, Y_test))\n\u001b[0m\u001b[1;32m     21\u001b[0m score, acc = model.evaluate(X_test, Y_test,\n\u001b[1;32m     22\u001b[0m                             batch_size=batch_size)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "#model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2))\n",
    "#model.add(Dense(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score, acc = model.evaluate(X_test, Y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(test.tweets.values)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.ones_like(y_pred_prob)\n",
    "y_pred[y_pred_prob<0.5] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = log.predict(test_2)\n",
    "y_pred = np.insert(prediction, index_to_remove_test -1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, 'w') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({'Id':int(r1),'Prediction':int(r2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(range(1,10001), y_pred, 'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 75.95%\n"
     ]
    }
   ],
   "source": [
    "solution = pd.read_csv('derived_solution.csv').Prediction\n",
    "print(\"Accuracy : {:.02f}%\".format(100*np.mean(solution == y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation with solver :\n",
    "- lbfgs : 75.66\n",
    "- newton-cg : 75.60%\n",
    "- sag : 75.69%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best on Aicrowd: (76.90%)\n",
    "- not full tweets\n",
    "- sag with C = 1, tol = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
